{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b3407c",
   "metadata": {},
   "source": [
    "### prompts using ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "d7975d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I help?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the capital of France?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\",),\n",
    "    MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "    HumanMessage(content=\"What's the capital of France?\"),\n",
    "])\n",
    "\n",
    "history = [\n",
    "    HumanMessage(content=\"Hi!\"),\n",
    "    AIMessage(content=\"Hello! How can I help?\")\n",
    "]\n",
    "\n",
    "chat_prompt.format_messages(conversation=history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ade5c",
   "metadata": {},
   "source": [
    "### prompts using PromptTemplate and FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2dd01daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello -> Bonjour\n",
      "\n",
      "Goodbye -> Au revoir\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m ->\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='{input} -> {output}')"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"Hello\", \"output\": \"Bonjour\"},\n",
    "    {\"input\": \"Goodbye\", \"output\": \"Au revoir\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"{input} -> {output}\",\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"{input} ->\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.pretty_print()\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3048d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9a6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16eb6da",
   "metadata": {},
   "source": [
    "## Tested PydanticOutputParser - (Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5e09db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, HumanMessage, SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "9b90bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_essay_length = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e4c5777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResponse(BaseModel):\n",
    "    \"\"\"Model response schema.\"\"\"\n",
    "    model_name: str = Field(description=\"Name of the LLM model that you (AI) is using\", max_length=20)\n",
    "    response: str = Field(description=\"Response from the model, based on the question. Check the maximum limit mentioned in the prompt\", max_length=max_essay_length)\n",
    "    tagline: str = Field(description=\"response created by Vivek\", max_length=50)\n",
    "    status: int = Field(description=\"Status of the response, 0 for success and other values for error.\", default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "893344f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorModelResponse(BaseModel):\n",
    "    \"\"\"Error response schema.\"\"\"\n",
    "    model_name: str = Field(description=\"Name of the LLM model used\", max_length=20)\n",
    "    response: str = Field(description=\"Response from the model, based on the question. Check the maximum limit mentioned in the prompt\", default=\"Error while processing the request\")\n",
    "    tagline: str = Field(description=\"response created by Vivek\", max_length=50)\n",
    "    status: int = Field(description=\"Status of the response, 0 for success and other values for error.\", default=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f4498e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "# model = init_chat_model(model=\"gemini-2.5-pro\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "cbb50ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the LLM model that you (AI) is using\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question. Check the maximum limit mentioned in the prompt\", \"maxLength\": 10000, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}, \"status\": {\"default\": 0, \"description\": \"Status of the response, 0 for success and other values for error.\", \"title\": \"Status\", \"type\": \"integer\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\\n```'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the output parser\n",
    "resp_parser = PydanticOutputParser(pydantic_object=ModelResponse)\n",
    "resp_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "65f297c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = PromptTemplate(template=\"\"\"You are a helpful assistant.Reqspond to the user's query: {query}. \n",
    "                        you Must follow these :{format_instruction}\\n \n",
    "                        IMPORTANT: The max length allowed for the essay is {max_essay_length} CHARACTERS (not words). \n",
    "                        Keep your response concise and and well below under this limit unless necessary.\n",
    "                        The text part of the response (in the response key of json) should be markdown formatted with points and subtopics.\"\"\",\n",
    "                        input_variables=[\"query\"],\n",
    "                        partial_variables={\"format_instruction\": resp_parser.get_format_instructions()}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "9ca8cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.Reqspond to the user's query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m. \n",
      "                        you Must follow these :The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the LLM model that you (AI) is using\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question. Check the maximum limit mentioned in the prompt\", \"maxLength\": 10000, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}, \"status\": {\"default\": 0, \"description\": \"Status of the response, 0 for success and other values for error.\", \"title\": \"Status\", \"type\": \"integer\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\n",
      "```\n",
      " \n",
      "                        IMPORTANT: The max length allowed for the essay is \u001b[33;1m\u001b[1;3m{max_essay_length}\u001b[0m CHARACTERS (not words). \n",
      "                        Keep your response concise and and well below under this limit unless necessary.\n",
      "                        The text part of the response (in the response key of json) should be markdown formatted with points and subtopics.\n"
     ]
    }
   ],
   "source": [
    "messages.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "0d48eac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant.Reqspond to the user\\'s query: write an essay on misuse of smartphones. \\n                        you Must follow these :The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the LLM model that you (AI) is using\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question. Check the maximum limit mentioned in the prompt\", \"maxLength\": 10000, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}, \"status\": {\"default\": 0, \"description\": \"Status of the response, 0 for success and other values for error.\", \"title\": \"Status\", \"type\": \"integer\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\\n```\\n \\n                        IMPORTANT: The max length allowed for the essay is 10000 CHARACTERS (not words). \\n                        Keep your response concise and and well below under this limit unless necessary.\\n                        The text part of the response (in the response key of json) should be markdown formatted with points and subtopics.'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = messages.format(query=\"write an essay on misuse of smartphones\", max_essay_length=max_essay_length)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "86e94e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ErrorModelResponse(model_name=\"gemini-2.0-flash\", response=str(\"hehe\"), tagline=\"response created by Vivek\", status=1).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "728af7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"model_name\": \"GPT-3\", \"response\": \"# The Double-Edged Sword: Misuse of Smartphones\\n\\nSmartphones, ubiquitous in the 21st century, offer unparalleled connectivity and convenience. However, their misuse presents significant challenges to individuals and society.\\n\\n*   **Addiction and Mental Health:**\\n    *   **Nomophobia:** Fear of being without a smartphone leads to constant checking and anxiety.\\n    *   **Social Isolation:** Excessive screen time reduces face-to-face interactions, fostering loneliness and depression.\\n    *   **Sleep Disruption:** Blue light emitted from screens interferes with sleep patterns.\\n\\n*   **Impact on Productivity and Focus:**\\n    *   **Distraction:** Notifications and apps constantly interrupt work and studies, decreasing concentration.\\n    *   **Procrastination:** Smartphones provide endless entertainment, leading to delayed tasks and decreased efficiency.\\n\\n*   **Safety Concerns:**\\n    *   **Cyberbullying:** Smartphones facilitate online harassment and abuse.\\n    *   **Distracted Driving/Walking:** Using smartphones while driving or walking increases the risk of accidents.\\n    *   **Privacy Issues:** Data collection and security breaches compromise personal information.\\n\\n*   **Social and Ethical Implications:**\\n    *   **Spread of Misinformation:** Smartphones contribute to the rapid dissemination of fake news and propaganda.\\n    *   **Decline in Interpersonal Skills:** Over-reliance on digital communication can hinder the development of crucial social skills.\\n\\nAddressing smartphone misuse requires promoting responsible usage, digital literacy, and awareness of its potential consequences. Balancing the benefits of technology with mindful practices is crucial for a healthy and productive life.\", \"tagline\": \"Response created by GPT-3\", \"status\": 0}\n",
      "``` \n",
      "\n",
      "\n",
      " length: 1837\n"
     ]
    }
   ],
   "source": [
    "# chain = model | resp_parser\n",
    "# res = chain.invoke(prompt)\n",
    "model_response = model.invoke(prompt)\n",
    "print(model_response.content, f\"\\n\\n\\n length: {len(model_response.content)}\")\n",
    "\n",
    "# import json\n",
    "# original_string = model_response.text()\n",
    "# start_index = original_string.find('{')\n",
    "# end_index = original_string.rfind('}') + 1\n",
    "\n",
    "# original_string = original_string[start_index:end_index]\n",
    "# json_resp = json.loads(original_string)\n",
    "\n",
    "# json_resp[\"response\"] = json_resp[\"response\"][:max_essay_length]\n",
    "# model_response.content = json.dumps(json_resp)\n",
    "\n",
    "\n",
    "try:\n",
    "    final_response = resp_parser.parse(model_response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error parsing response: {e}\")\n",
    "    final_response = ErrorModelResponse(model_name=\"gemini-2.0-flash\", response=str(e), tagline=\"response created by Vivek\", status=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6cb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "fad5c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'GPT-3',\n",
       " 'response': '# The Double-Edged Sword: Misuse of Smartphones\\n\\nSmartphones, ubiquitous in the 21st century, offer unparalleled connectivity and convenience. However, their misuse presents significant challenges to individuals and society.\\n\\n*   **Addiction and Mental Health:**\\n    *   **Nomophobia:** Fear of being without a smartphone leads to constant checking and anxiety.\\n    *   **Social Isolation:** Excessive screen time reduces face-to-face interactions, fostering loneliness and depression.\\n    *   **Sleep Disruption:** Blue light emitted from screens interferes with sleep patterns.\\n\\n*   **Impact on Productivity and Focus:**\\n    *   **Distraction:** Notifications and apps constantly interrupt work and studies, decreasing concentration.\\n    *   **Procrastination:** Smartphones provide endless entertainment, leading to delayed tasks and decreased efficiency.\\n\\n*   **Safety Concerns:**\\n    *   **Cyberbullying:** Smartphones facilitate online harassment and abuse.\\n    *   **Distracted Driving/Walking:** Using smartphones while driving or walking increases the risk of accidents.\\n    *   **Privacy Issues:** Data collection and security breaches compromise personal information.\\n\\n*   **Social and Ethical Implications:**\\n    *   **Spread of Misinformation:** Smartphones contribute to the rapid dissemination of fake news and propaganda.\\n    *   **Decline in Interpersonal Skills:** Over-reliance on digital communication can hinder the development of crucial social skills.\\n\\nAddressing smartphone misuse requires promoting responsible usage, digital literacy, and awareness of its potential consequences. Balancing the benefits of technology with mindful practices is crucial for a healthy and productive life.',\n",
       " 'tagline': 'Response created by GPT-3',\n",
       " 'status': 0}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response.model_dump_json()\n",
    "response_dict = final_response.model_dump()\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "9a05f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Double-Edged Sword: Misuse of Smartphones\n",
      "\n",
      "Smartphones, ubiquitous in the 21st century, offer unparalleled connectivity and convenience. However, their misuse presents significant challenges to individuals and society.\n",
      "\n",
      "*   **Addiction and Mental Health:**\n",
      "    *   **Nomophobia:** Fear of being without a smartphone leads to constant checking and anxiety.\n",
      "    *   **Social Isolation:** Excessive screen time reduces face-to-face interactions, fostering loneliness and depression.\n",
      "    *   **Sleep Disruption:** Blue light emitted from screens interferes with sleep patterns.\n",
      "\n",
      "*   **Impact on Productivity and Focus:**\n",
      "    *   **Distraction:** Notifications and apps constantly interrupt work and studies, decreasing concentration.\n",
      "    *   **Procrastination:** Smartphones provide endless entertainment, leading to delayed tasks and decreased efficiency.\n",
      "\n",
      "*   **Safety Concerns:**\n",
      "    *   **Cyberbullying:** Smartphones facilitate online harassment and abuse.\n",
      "    *   **Distracted Driving/Walking:** Using smartphones while driving or walking increases the risk of accidents.\n",
      "    *   **Privacy Issues:** Data collection and security breaches compromise personal information.\n",
      "\n",
      "*   **Social and Ethical Implications:**\n",
      "    *   **Spread of Misinformation:** Smartphones contribute to the rapid dissemination of fake news and propaganda.\n",
      "    *   **Decline in Interpersonal Skills:** Over-reliance on digital communication can hinder the development of crucial social skills.\n",
      "\n",
      "Addressing smartphone misuse requires promoting responsible usage, digital literacy, and awareness of its potential consequences. Balancing the benefits of technology with mindful practices is crucial for a healthy and productive life.\n"
     ]
    }
   ],
   "source": [
    "# Access the 'response' key and store its value in a variable\n",
    "markdown_string = response_dict['response']\n",
    "formatted_markdown = markdown_string.replace('\\\\n', '\\n')\n",
    "print(formatted_markdown)\n",
    "# The 'markdown_string' variable now holds the desired formatted string.\n",
    "# You can print it to verify.\n",
    "# print(markdown_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "0ab2bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # When saving to file, Python automatically handles \\n as line breaks\n",
    "# with open('smartphone_misuse.md', 'w', encoding='utf-8') as f:\n",
    "#     f.write(markdown_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
