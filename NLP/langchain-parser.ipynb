{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b3407c",
   "metadata": {},
   "source": [
    "### prompts using ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d7975d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I help?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's the capital of France?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful assistant.\",),\n",
    "    MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "    HumanMessage(content=\"What's the capital of France?\"),\n",
    "])\n",
    "\n",
    "history = [\n",
    "    HumanMessage(content=\"Hi!\"),\n",
    "    AIMessage(content=\"Hello! How can I help?\")\n",
    "]\n",
    "\n",
    "chat_prompt.format_messages(conversation=history)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ade5c",
   "metadata": {},
   "source": [
    "### prompts using PromptTemplate and FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2dd01daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello -> Bonjour\n",
      "\n",
      "Goodbye -> Au revoir\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{input}\u001b[0m ->\n",
      "--------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='{input} -> {output}')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "# from langchain.llms import OpenAI\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"Hello\", \"output\": \"Bonjour\"},\n",
    "    {\"input\": \"Goodbye\", \"output\": \"Au revoir\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"{input} -> {output}\",\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"{input} ->\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.pretty_print()\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3048d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9a6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16eb6da",
   "metadata": {},
   "source": [
    "## Tested PydanticOutputParser - (Working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5e09db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser, JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, FewShotPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import (\n",
    "    AIMessage, HumanMessage, SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9b90bee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_essay_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e4c5777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResponse(BaseModel):\n",
    "    \"\"\"Model response schema.\"\"\"\n",
    "    model_name: str = Field(description=\"Name of the model\", max_length=20)\n",
    "    response: str = Field(description=\"Response from the model, based on the question\", max_length=max_essay_length)\n",
    "    tagline: str = Field(description=\"response created by Vivek\", max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5130f2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the model\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question\", \"maxLength\": 500, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\\n```'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_parser = PydanticOutputParser(pydantic_object=ModelResponse)\n",
    "resp_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f4498e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"gemini-2.0-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "65f297c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = PromptTemplate(template=\"\"\"You are a helpful assistant.Reqspond to the user's query: {query}. \n",
    "                        you Must follow these :{format_instruction}\\n \n",
    "                        IMPORTANT: The max length allowed for the essay is {max_essay_length} CHARACTERS (not words). \n",
    "                        Keep your response concise and under this limit\"\"\",\n",
    "                        input_variables=[\"query\"],\n",
    "                        partial_variables={\"format_instruction\": resp_parser.get_format_instructions()}\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9ca8cb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant.Reqspond to the user's query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m. \n",
      "                        you Must follow these :The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the model\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question\", \"maxLength\": 500, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\n",
      "```\n",
      " \n",
      "                        IMPORTANT: The max length allowed for the essay is \u001b[33;1m\u001b[1;3m{max_essay_length}\u001b[0m CHARACTERS (not words). \n",
      "                        Keep your response concise and under this limit\n"
     ]
    }
   ],
   "source": [
    "messages.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "0d48eac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a helpful assistant.Reqspond to the user\\'s query: write an essay on misuse of smartphones. \\n                        you Must follow these :The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Model response schema.\", \"properties\": {\"model_name\": {\"description\": \"Name of the model\", \"maxLength\": 20, \"title\": \"Model Name\", \"type\": \"string\"}, \"response\": {\"description\": \"Response from the model, based on the question\", \"maxLength\": 500, \"title\": \"Response\", \"type\": \"string\"}, \"tagline\": {\"description\": \"response created by Vivek\", \"maxLength\": 50, \"title\": \"Tagline\", \"type\": \"string\"}}, \"required\": [\"model_name\", \"response\", \"tagline\"]}\\n```\\n \\n                        IMPORTANT: The max length allowed for the essay is 500 CHARACTERS (not words). \\n                        Keep your response concise and under this limit'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = messages.format(query=\"write an essay on misuse of smartphones\", max_essay_length=max_essay_length)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "728af7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\"model_name\": \"EssayWriter\", \"response\": \"Smartphones, while useful, are often misused. Overuse leads to addiction, impacting mental health & productivity. Excessive screen time strains eyes and disrupts sleep. Social isolation and cyberbullying are also concerns. Prioritizing real-life interactions is crucial.\", \"tagline\": \"Created by Vivek for responsible tech use.\"}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# chain = model | resp_parser\n",
    "# res = chain.invoke(prompt)\n",
    "model_response = model.invoke(prompt)\n",
    "print(model_response.content)\n",
    "\n",
    "final_response = resp_parser.parse(model_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "fad5c096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'EssayWriter',\n",
       " 'response': 'Smartphones, while useful, are often misused. Overuse leads to addiction, impacting mental health & productivity. Excessive screen time strains eyes and disrupts sleep. Social isolation and cyberbullying are also concerns. Prioritizing real-life interactions is crucial.',\n",
       " 'tagline': 'Created by Vivek for responsible tech use.'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response.model_dump_json()\n",
    "response_dict = final_response.model_dump()\n",
    "response_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
