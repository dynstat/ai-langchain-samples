{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gUR8bNFEwLUW",
        "outputId": "57476149-93c8-47b4-a31c-779a889cc6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain[google-genai] in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (6.0.1)\n",
            "Requirement already satisfied: langchain-google-genai in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.1.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (2024.2.2)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.1.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (3.10.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.23.0)\n",
            "Requirement already satisfied: anyio in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai->langchain[google-genai])\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.39.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n",
            "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "Successfully installed google-ai-generativelanguage-0.6.18\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install \"langchain[google-genai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0tua7wH03Qsy",
        "outputId": "b73487dc-35b5-4f6a-ca40-5473d304a489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in d:\\pyinstallfolder\\py312\\lib\\site-packages (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# !pip install langchain-huggingface\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7RxAQZvdou",
        "outputId": "8b5b4398-6d82-4ad9-a51b-e29b667e39d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(r\"D:\\py_prac\\langchain-prac\\.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQJONHz2z7aJ"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eYaA78e0Esd",
        "outputId": "bfbcbb89-fb66-4c4d-9e8e-2e40eba67cc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'lc': 1,\n",
              " 'type': 'constructor',\n",
              " 'id': ['langchain', 'schema', 'messages', 'AIMessage'],\n",
              " 'kwargs': {'content': 'I am a large language model, trained by Google.',\n",
              "  'response_metadata': {'prompt_feedback': {'block_reason': 0,\n",
              "    'safety_ratings': []},\n",
              "   'finish_reason': 'STOP',\n",
              "   'model_name': 'gemini-2.0-flash',\n",
              "   'safety_ratings': []},\n",
              "  'type': 'ai',\n",
              "  'id': 'run--c3b0dfa6-4a98-4f96-b510-b7239f71756d-0',\n",
              "  'usage_metadata': {'input_tokens': 6,\n",
              "   'output_tokens': 12,\n",
              "   'total_tokens': 18,\n",
              "   'input_token_details': {'cache_read': 0}},\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_resp = model.invoke(\"who are you, which model\")\n",
        "model_resp.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4daoKuQqBrX3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOZv-3UWBr1P",
        "outputId": "b1008af1-35b8-4bad-ce6e-c429330b5da7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'अनुवाद: नमस्ते!\\nउदाहरण: नमस्ते, आप कैसे हैं?'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into hindi. also add an example of the translation in a sentence. Do not use any other language in the response. Use the format: 'Translation: <translated text>. Example: <example sentence in hindi>'.\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "resp = model.invoke(messages)\n",
        "resp.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "cPtXzrQUBzEP",
        "outputId": "64691476-bb1c-436d-e5d8-727fb81831d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bzt_8cjfB2l_",
        "outputId": "299b64e1-bed0-48bc-a385-d0a5ba140b96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__add__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__class_vars__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_pydantic_core_schema__',\n",
              " '__get_pydantic_json_schema__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__pydantic_complete__',\n",
              " '__pydantic_computed_fields__',\n",
              " '__pydantic_core_schema__',\n",
              " '__pydantic_custom_init__',\n",
              " '__pydantic_decorators__',\n",
              " '__pydantic_extra__',\n",
              " '__pydantic_fields__',\n",
              " '__pydantic_fields_set__',\n",
              " '__pydantic_generic_metadata__',\n",
              " '__pydantic_init_subclass__',\n",
              " '__pydantic_parent_namespace__',\n",
              " '__pydantic_post_init__',\n",
              " '__pydantic_private__',\n",
              " '__pydantic_root_model__',\n",
              " '__pydantic_serializer__',\n",
              " '__pydantic_setattr_handlers__',\n",
              " '__pydantic_validator__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__replace__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_recursion__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_backwards_compat_tool_calls',\n",
              " '_calculate_keys',\n",
              " '_copy_and_set_values',\n",
              " '_get_value',\n",
              " '_iter',\n",
              " '_setattr_handler',\n",
              " 'additional_kwargs',\n",
              " 'construct',\n",
              " 'content',\n",
              " 'copy',\n",
              " 'dict',\n",
              " 'example',\n",
              " 'from_orm',\n",
              " 'get_lc_namespace',\n",
              " 'id',\n",
              " 'invalid_tool_calls',\n",
              " 'is_lc_serializable',\n",
              " 'json',\n",
              " 'lc_attributes',\n",
              " 'lc_id',\n",
              " 'lc_secrets',\n",
              " 'model_computed_fields',\n",
              " 'model_config',\n",
              " 'model_construct',\n",
              " 'model_copy',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_extra',\n",
              " 'model_fields',\n",
              " 'model_fields_set',\n",
              " 'model_json_schema',\n",
              " 'model_parametrized_name',\n",
              " 'model_post_init',\n",
              " 'model_rebuild',\n",
              " 'model_validate',\n",
              " 'model_validate_json',\n",
              " 'model_validate_strings',\n",
              " 'name',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'pretty_print',\n",
              " 'pretty_repr',\n",
              " 'response_metadata',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'text',\n",
              " 'to_json',\n",
              " 'to_json_not_implemented',\n",
              " 'tool_calls',\n",
              " 'type',\n",
              " 'update_forward_refs',\n",
              " 'usage_metadata',\n",
              " 'validate']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEnp8ZXwB8j7",
        "outputId": "d8303541-f1a1-4b34-c9a2-6639b78763b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "अनुवाद: नमस्ते!\n",
            "उदाहरण: नमस्ते, आप कैसे हैं?\n"
          ]
        }
      ],
      "source": [
        "resp.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tNuTWsJCOdm",
        "outputId": "a7d1e636-11b9-439e-9c8a-732af7834739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "अनु<..>वाद: नमस्ते!\n",
            "उदाहरण: नमस्ते! आप कैसे हैं?\n",
            "<..>"
          ]
        }
      ],
      "source": [
        "for token in model.stream(messages):\n",
        "    print(token.content, end=\"<..>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Xdb6u3LWHH"
      },
      "source": [
        "Streaming with async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6USit7dzCOT-",
        "outputId": "143712d1-aa72-4b81-b0b9-c4709bc9f602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(... Verse 1... )\n",
            "In a bowl of moondust, a goldfish does reside,\n",
            "Swimming...  through craters, with nowhere to hide.\n",
            "He flicks his orange tail, in...  zero gravity's sway,\n",
            "Dreaming of kelp forests, so very far away.\n",
            "He stares back at Earth, a blue and swirling gem,\n",
            "A...  forgotten memory, a watery diadem.\n",
            "No bubbles to burst, no surface to reach,\n",
            "Just lunar landscapes, beyond mortal speech.\n",
            "He nibbles on moon...  rocks, a cosmic cuisine,\n",
            "A solitary explorer, in a silver screen.\n",
            "He wonders if anyone, down on the ground,\n",
            "Sees his tiny spaceship, where he's forever bound.\n",
            "A goldfish on the moon, a whimsical...  plight,\n",
            "A shimmering beacon, in the endless night.\n",
            "... "
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize the chat model\n",
        "chatmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "\n",
        "# Use async directly at the top level in Jupyter, ignore the error or just wrap the api call in the async function and just await that function (without a new async loop)\n",
        "async for chunk in chatmodel.astream(\"Write me a 1 verse song about goldfish on the moon, of 150 words.\"):\n",
        "    print(chunk.content, end=\"... \", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il6E2nWvK2qC"
      },
      "source": [
        "OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkJKPIiTKqtp",
        "outputId": "900d2956-a0cc-469a-a2fe-b1ba5057605c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In| a silver bowl of stardust bright,\n",
            "Swim goldfish, orange in the lunar| light.\n",
            "No gravity holds, they float and they gleam,\n",
            "A| silent ballet, a moonlit dream.\n",
            "|"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# nest_asyncio.apply()  # Patch the running event loop\n",
        "\n",
        "async def main():\n",
        "    chatmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "    async for chunk in chatmodel.astream(\"Write me a 1 verse song about goldfish on the moon\"):\n",
        "        print(chunk.content, end=\"|\", flush=True)\n",
        "\n",
        "# Works now in Colab/Jupyter\n",
        "await main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWH32B8lP5sY"
      },
      "source": [
        "ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWH-n6YvLZtq",
        "outputId": "1e35d01e-c52e-4f21-a864-2150a1f93371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "# prompt_template = ChatPromptTemplate.from_messages(\n",
        "#     [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        "# )\n",
        "prompt = prompt_template.invoke({\"language\": \"hindi\", \"text\": \"hi!\"})\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b9Nbu_gyLZq_",
        "outputId": "da0ce27d-addb-4e1d-eb21-a04627aca478"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__class_vars__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_pydantic_core_schema__',\n",
              " '__get_pydantic_json_schema__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__pydantic_complete__',\n",
              " '__pydantic_computed_fields__',\n",
              " '__pydantic_core_schema__',\n",
              " '__pydantic_custom_init__',\n",
              " '__pydantic_decorators__',\n",
              " '__pydantic_extra__',\n",
              " '__pydantic_fields__',\n",
              " '__pydantic_fields_set__',\n",
              " '__pydantic_generic_metadata__',\n",
              " '__pydantic_init_subclass__',\n",
              " '__pydantic_parent_namespace__',\n",
              " '__pydantic_post_init__',\n",
              " '__pydantic_private__',\n",
              " '__pydantic_root_model__',\n",
              " '__pydantic_serializer__',\n",
              " '__pydantic_setattr_handlers__',\n",
              " '__pydantic_validator__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__replace__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_recursion__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_calculate_keys',\n",
              " '_copy_and_set_values',\n",
              " '_get_value',\n",
              " '_iter',\n",
              " '_setattr_handler',\n",
              " 'construct',\n",
              " 'copy',\n",
              " 'dict',\n",
              " 'from_orm',\n",
              " 'get_lc_namespace',\n",
              " 'is_lc_serializable',\n",
              " 'json',\n",
              " 'lc_attributes',\n",
              " 'lc_id',\n",
              " 'lc_secrets',\n",
              " 'messages',\n",
              " 'model_computed_fields',\n",
              " 'model_config',\n",
              " 'model_construct',\n",
              " 'model_copy',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_extra',\n",
              " 'model_fields',\n",
              " 'model_fields_set',\n",
              " 'model_json_schema',\n",
              " 'model_parametrized_name',\n",
              " 'model_post_init',\n",
              " 'model_rebuild',\n",
              " 'model_validate',\n",
              " 'model_validate_json',\n",
              " 'model_validate_strings',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'to_json',\n",
              " 'to_json_not_implemented',\n",
              " 'to_messages',\n",
              " 'to_string',\n",
              " 'update_forward_refs',\n",
              " 'validate']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU7aUZYdLZoG",
        "outputId": "53aa4fc5-4906-4693-e533-4633fbc7608d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following from English into hindi', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltfevCFXLZlb",
        "outputId": "ec92f265-0fc9-4505-c20d-e3a2da23e464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "नमस्ते! (Namaste!)\n",
            "\n",
            "You can also say:\n",
            "\n",
            "*   हेलो! (Hello!)\n",
            "*   हाय! (Hi!) - This is a direct transliteration of \"Hi\" and is commonly used, especially among younger people.\n"
          ]
        }
      ],
      "source": [
        "response = model.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The most common and direct translation of \"hi!\" into Sanskrit would be:\n",
            "\n",
            "**नमस्ते (Namaste)**\n",
            "\n",
            "This is a standard greeting that conveys respect and goodwill.\n",
            "\n",
            "While less common, you could also use:\n",
            "\n",
            "*   **शुभम् (Shubham)** - This means \"auspicious\" or \"well-being,\" and can be used as a greeting, wishing someone well.\n",
            "*   **स्वस्ति (Svasti)** - This means \"well-being\" or \"good fortune.\"\n",
            "*   **अहो (Aho)** - This is similar to \"O!\" or \"Hey!\" and is more of an interjection.\n",
            "\n",
            "However, **नमस्ते (Namaste)** is the most widely recognized and appropriate translation for \"hi!\" in most situations.\n"
          ]
        }
      ],
      "source": [
        "chain = prompt_template | model\n",
        "response = chain.invoke({\"language\": \"sanskrit\", \"text\": \"hi!\"})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lQA1OcZCTECq",
        "outputId": "8d98c8b2-cbd6-4787-d6f3-a73155361bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.8.5)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.39.0)\n",
            "Requirement already satisfied: protobuf in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: colorama in d:\\pyinstallfolder\\py312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
            "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
            "Successfully installed google-ai-generativelanguage-0.6.15\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.7 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install google-generativeai --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T7ApKYZrTD-9"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import time\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Upload file\n",
        "file = client.files.upload(file=r\"D:\\py_prac\\langchain-prac\\datasets\\CPlusPlusNotesForProfessionals.pdf\")\n",
        "while file.state.name == 'PROCESSING':\n",
        "    print(f\"File {file.name} is still processing...\")\n",
        "    # Wait for processing to complete\n",
        "    time.sleep(2)\n",
        "    file = client.files.get(name=file.name)\n",
        "\n",
        "# Create cache\n",
        "model = 'gemini-2.0-flash'\n",
        "cache = client.caches.create(\n",
        "    model=model,\n",
        "    config=types.CreateCachedContentConfig(\n",
        "        display_name='Cached Content',\n",
        "        system_instruction=(\n",
        "            \"You are an expert content analyzer, and your job is to answer the user's query based on the file you have access to.\"\n",
        "        ),\n",
        "        contents=[file],\n",
        "        ttl=\"3000s\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Query with LangChain\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model,\n",
        "    cached_content=cache.name,\n",
        ")\n",
        "message = HumanMessage(content=\"Summarize the main points of the content.\")\n",
        "airesponse = llm.invoke([message])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The document is a comprehensive guide to C++ programming, covering a wide array of topics from basic syntax and data types to advanced concepts like metaprogramming, memory management, and concurrency. Here\\'s a summary organized by key areas:\\n\\n*   **Fundamentals:** Covers the basics of C++, including program structure, comments, compilation, functions, and variable declarations.\\n\\n*   **Core Language Features:** Explores literals, operator precedence, bit operators, bit manipulation, arrays, iterators, and basic input/output.\\n\\n*   **Flow Control:** Discusses loops (for, while, do-while), loop control statements (break, continue), and conditional structures (if, else).\\n\\n*   **File I/O:** Details how to read from and write to files using C++ streams.\\n\\n*   **C++ Streams and Manipulators:** Explains the use of C++ streams for string manipulation and printing collections, as well as stream manipulators for formatting output.\\n\\n*   **Polymorphism and Inheritance:** Covers polymorphic classes, safe downcasting, and the importance of virtual destructors.\\n\\n*   **References and Memory Management:** Discusses references, value and reference semantics, function call mechanics, and smart pointers.\\n\\n*   **Classes and Structures:** Explores class basics, access specifiers, inheritance, friendship, virtual inheritance, and member functions.\\n\\n*   **Function and Operator Overloading:** Details function overloading, operator overloading, and their applications.\\n\\n*   **Templates:** Covers basic class and function templates, variadic templates, argument forwarding, and template specialization.\\n\\n*   **Advanced Topics:** Includes metaprogramming, the `const` and `mutable` keywords, the \"this\" pointer, the Pimpl Idiom, type erasure, and undefined behavior.\\n\\n*   **Concurrency:** Explores threading, thread synchronization structures, futures and promises, and atomic types.\\n\\n*   **Modern C++ Features:** Highlights features introduced in C++11, C++14, C++17, and C++20, including `constexpr`, `noexcept`, user-defined literals, and structured bindings.\\n\\n*   **Debugging and Optimization:** Discusses debugging techniques, static analysis, and optimization strategies such as inline expansion and empty base optimization.\\n\\n*   **Design Patterns:** Provides examples of implementing design patterns like Adapter, Observer, Singleton, and Builder in C++.\\n\\n*   **Standard Library Components:** Explores various components of the C++ Standard Library, such as `std::string`, `std::array`, `std::vector`, `std::map`, `std::optional`, `std::function`, and various algorithms.\\n\\n*   **Implementation-Defined Behavior and Incompatibilities:** Notes potential issues such as size of integral types, character encodings, and C incompatibilities.\\n\\nThe document is intended as a practical guide for C++ programmers, offering detailed explanations, code examples, and best practices for a wide range of common tasks and advanced techniques.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airesponse.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'There is no mention of Python in the document.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke([HumanMessage(content=\"Tell me about the python related part in this pdf\")]).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3JCr5thUFyU",
        "outputId": "d529652a-531a-4d52-badc-2f779746801d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CachedContent(name='cachedContents/tose3ga85k1mfgvqlxqh92ncuxu546o7o8cvi8qx', display_name='Cached Content', model='models/gemini-2.0-flash', create_time=datetime.datetime(2025, 7, 12, 12, 41, 7, 300660, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 7, 12, 12, 41, 7, 300660, tzinfo=TzInfo(UTC)), expire_time=datetime.datetime(2025, 7, 12, 13, 31, 6, 405315, tzinfo=TzInfo(UTC)), usage_metadata=CachedContentUsageMetadata(audio_duration_seconds=None, image_count=None, text_count=None, total_token_count=182693, video_duration_seconds=None))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5S7iL7pTA_pw",
        "outputId": "30a34e8a-28cb-4c68-f0be-4d13c13d3e9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_aio',\n",
              " '_api_client',\n",
              " '_batches',\n",
              " '_caches',\n",
              " '_debug_config',\n",
              " '_files',\n",
              " '_get_api_client',\n",
              " '_models',\n",
              " '_operations',\n",
              " '_tunings',\n",
              " 'aio',\n",
              " 'batches',\n",
              " 'caches',\n",
              " 'chats',\n",
              " 'files',\n",
              " 'models',\n",
              " 'operations',\n",
              " 'tunings',\n",
              " 'vertexai']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0VXDeohBDlX",
        "outputId": "3d5cb9ad-1008-43a5-efb8-e9c39fb0218a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<google.genai.caches.Caches at 0x1f65e1ff7d0>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.caches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "osGiNj_jBYzC",
        "outputId": "abbfb306-aa0b-4ec1-f9c5-3b475e6ce8a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'files/wp8hxo7y4hki'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEYC9jeeBklC",
        "outputId": "9146a11e-9361-42de-c34e-47c1189f657e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# client.caches.get(name=\"files/rvmpfysdfu0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U64EFXRRAl-O",
        "outputId": "935269d6-0095-4098-8be2-55c6ce333317"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ACTIVE'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file.state.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "HKDLslIKTD7N",
        "outputId": "99c3c662-16a7-4292-f7df-c95983572de6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(airesponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "3rYpWP5ksWzs",
        "outputId": "58b7f964-9684-420c-8985-4cbd943c7b41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The document is a comprehensive guide to C++ programming, covering a wide array of topics from basic syntax and data types to advanced concepts like metaprogramming, memory management, and concurrency. Here\\'s a summary organized by key areas:\\n\\n*   **Fundamentals:** Covers the basics of C++, including program structure, comments, compilation, functions, and variable declarations.\\n\\n*   **Core Language Features:** Explores literals, operator precedence, bit operators, bit manipulation, arrays, iterators, and basic input/output.\\n\\n*   **Flow Control:** Discusses loops (for, while, do-while), loop control statements (break, continue), and conditional structures (if, else).\\n\\n*   **File I/O:** Details how to read from and write to files using C++ streams.\\n\\n*   **C++ Streams and Manipulators:** Explains the use of C++ streams for string manipulation and printing collections, as well as stream manipulators for formatting output.\\n\\n*   **Polymorphism and Inheritance:** Covers polymorphic classes, safe downcasting, and the importance of virtual destructors.\\n\\n*   **References and Memory Management:** Discusses references, value and reference semantics, function call mechanics, and smart pointers.\\n\\n*   **Classes and Structures:** Explores class basics, access specifiers, inheritance, friendship, virtual inheritance, and member functions.\\n\\n*   **Function and Operator Overloading:** Details function overloading, operator overloading, and their applications.\\n\\n*   **Templates:** Covers basic class and function templates, variadic templates, argument forwarding, and template specialization.\\n\\n*   **Advanced Topics:** Includes metaprogramming, the `const` and `mutable` keywords, the \"this\" pointer, the Pimpl Idiom, type erasure, and undefined behavior.\\n\\n*   **Concurrency:** Explores threading, thread synchronization structures, futures and promises, and atomic types.\\n\\n*   **Modern C++ Features:** Highlights features introduced in C++11, C++14, C++17, and C++20, including `constexpr`, `noexcept`, user-defined literals, and structured bindings.\\n\\n*   **Debugging and Optimization:** Discusses debugging techniques, static analysis, and optimization strategies such as inline expansion and empty base optimization.\\n\\n*   **Design Patterns:** Provides examples of implementing design patterns like Adapter, Observer, Singleton, and Builder in C++.\\n\\n*   **Standard Library Components:** Explores various components of the C++ Standard Library, such as `std::string`, `std::array`, `std::vector`, `std::map`, `std::optional`, `std::function`, and various algorithms.\\n\\n*   **Implementation-Defined Behavior and Incompatibilities:** Notes potential issues such as size of integral types, character encodings, and C incompatibilities.\\n\\nThe document is intended as a practical guide for C++ programmers, offering detailed explanations, code examples, and best practices for a wide range of common tasks and advanced techniques.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airesponse.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8IdRl1vzYxi"
      },
      "source": [
        "## Agent using langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lk_sCcrrGwum",
        "outputId": "5996cd37-f9d7-43f5-8393-86c175dd1845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langgraph in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.5.2)\n",
            "Requirement already satisfied: langchain-tavily in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.2.7)\n",
            "Requirement already satisfied: langgraph-checkpoint-sqlite in d:\\pyinstallfolder\\py312\\lib\\site-packages (2.0.10)\n",
            "Requirement already satisfied: langchain-core>=0.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (0.3.68)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.6.0,>=0.5.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (0.5.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (0.1.72)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (2.11.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-tavily) (3.12.14)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-tavily) (0.3.26)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-tavily) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.20.1)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core>=0.1->langgraph) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2024.2.2)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.1.1)\n",
            "Requirement already satisfied: aiosqlite>=0.20 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph-checkpoint-sqlite) (0.21.0)\n",
            "Requirement already satisfied: sqlite-vec>=0.1.6 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langgraph-checkpoint-sqlite) (0.1.6)\n",
            "Requirement already satisfied: anyio in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langgraph langchain-tavily langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8KfVjPVWGwr6"
      },
      "outputs": [],
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5WSgB1PG0tBN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "  os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter API key for TAVILY_API_KEY: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sFXnvYSGwpF",
        "outputId": "237b43a1-c151-41d3-9a62-0e6be463edaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'What is the weather in New Delhi', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752324285, 'localtime': '2025-07-12 18:14'}, 'current': {'last_updated_epoch': 1752323400, 'last_updated': '2025-07-12 18:00', 'temp_c': 37.5, 'temp_f': 99.5, 'is_day': 1, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 177, 'wind_dir': 'S', 'pressure_mb': 998.0, 'pressure_in': 29.48, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 35, 'cloud': 30, 'feelslike_c': 41.0, 'feelslike_f': 105.8, 'windchill_c': 37.5, 'windchill_f': 99.5, 'heatindex_c': 41.0, 'heatindex_f': 105.8, 'dewpoint_c': 19.3, 'dewpoint_f': 66.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.1, 'gust_mph': 4.5, 'gust_kph': 7.2}}\", 'score': 0.9028875, 'raw_content': None}, {'url': 'https://world-weather.info/forecast/india/delhi/july-2025/', 'title': 'Weather in Delhi in July 2025', 'content': \"Weather in Delhi in July 2025 (Union Territory of Delhi) - Detailed Weather Forecast for a Month Weather World Weather in Delhi Weather in Delhi in July 2025 Delhi Weather Forecast for July 2025, is based on previous years' statistical data. +100°+90° +99°+88° +97°+88° +97°+88° +95°+86° +93°+84° +97°+88° +97°+88° +95°+86° +97°+88° +95°+84° +93°+86° +95°+88° +95°+86° +95°+86° +95°+88° +93°+84° +93°+84° +95°+86° +95°+84° +93°+84° +93°+86° +93°+84° +95°+86° +93°+84° +91°+82° +91°+84° +93°+84° +91°+82° +93°+84° +93°+84° Extended weather forecast in Delhi HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in New Delhi+91° Panipat+93° Muzaffarnagar+95° Karnāl+95° Aligarh+95° Alwar+95° Mathura+95° Sahāranpur+93° Morādābād+95° Rohtak+93° Meerut+93° Okhla Industrial Development Area+88° Nāngloi Jāt+88° Ghaziabad+91° Noida+93° Faridabad+88° Gurgaon+88° Sonīpat+91° world's temperature today day day Weather forecast on your site Install Delhi+88°\", 'score': 0.8839694, 'raw_content': None}], 'response_time': 1.61}\n"
          ]
        }
      ],
      "source": [
        "search = TavilySearch(max_results=2)\n",
        "search_results = search.invoke(\"What is the weather in New Delhi\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "# from pydantic import BaseModel\n",
        "\n",
        "# class SearchInput(BaseModel):\n",
        "#     query: str\n",
        "\n",
        "@tool\n",
        "def searchtool(query) -> str:\n",
        "    \"\"\"Search the web for recent information about anything you don't know.\"\"\"\n",
        "    print(f\"In the search tool now: params i got - > query:{query}\")\n",
        "    result = search.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "tools = [searchtool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NnkA8js3XG3Z"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "HSehtt_KGwmN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hi V! It's nice to meet you. How can I help you today?\""
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Hi! i am V\"\n",
        "# response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "# OR \n",
        "response = model.invoke([HumanMessage(content=query)])\n",
        "response.text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rV3OE9X1GwiO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Message content: \n",
            "\n",
            "Tool calls: [{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': '3e7a6e6d-70f9-4e57-8a56-93dd83f47ffc', 'type': 'tool_call'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
        "\n",
        "model_plus_tools = model.bind_tools(tools)\n",
        "\n",
        "query = \"What is the weather in New Delhi?\"\n",
        "# response = model_plus_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "response = model_plus_tools.invoke([HumanMessage(content=query)])\n",
        "\n",
        "print(f\"Message content: {response.text()}\\n\")\n",
        "# here there is no response but as we can see that the tool is being MARKED TO BE called.\n",
        "print(f\"Tool calls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EkLso4_fd21V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'searchtool',\n",
              " 'args': {'query': 'weather in New Delhi'},\n",
              " 'id': '3e7a6e6d-70f9-4e57-8a56-93dd83f47ffc',\n",
              " 'type': 'tool_call'}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.tool_calls[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': '3e7a6e6d-70f9-4e57-8a56-93dd83f47ffc', 'type': 'tool_call'}\n",
            "args =  {'query': 'weather in New Delhi'}\n",
            "\n",
            "\n",
            " ------------------ Okay, dost! Here's the weather report for New Delhi, straight from the source, but in Hinglish and easy to understand:\n",
            "\n",
            "*   **Location:** New Delhi, Delhi, India. Apni Dilli!\n",
            "*   **Time:** Abhi baj rahe hain 6:14 PM (shaam ke), 12th July, 2025.\n",
            "*   **Temperature:** 37.5 degrees Celsius (garmi hai bhai!), which is like 99.5 degrees Fahrenheit.\n",
            "*   **Condition:** Partly Cloudy. Thode badal hai, thodi dhoop.\n",
            "*   **Wind:** Hawa chal rahi hai 6.1 kilometers per hour se.\n",
            "*   **Humidity:** 35%. Itni bhi zyada nami nahi hai.\n",
            "*   **Feels Like:** Lagbhag 41 degrees Celsius (105.8 Fahrenheit). Toh matlab, asal temperature se zyada garam lagega!\n",
            "*   **Important Note:** Heat index bhi 41 degrees Celsius hai. Toh dhyan rakhna, dehydrate mat hona. Pani peete rehna!\n",
            "*   **UV Index:** UV index 0.1 hai.\n",
            "\n",
            "So, basically, garmi hai Dilli mein! Pani peete rehna aur dhoop se bachke rehna. Have a good evening! 😄\n"
          ]
        }
      ],
      "source": [
        "# Now to actually call the tool, we need to use the tool calls in the response.\n",
        "# Now we can call the tool with the tool call.\n",
        "tool_call = response.tool_calls[0]\n",
        "print(tool_call)\n",
        "print(\"args = \", tool_call[\"args\"])\n",
        "tool_response = search.invoke(tool_call[\"args\"])\n",
        "tool_response_content = tool_response[\"results\"][0]\n",
        "final_response = model.invoke([AIMessage(content=str(tool_response_content)), HumanMessage(content=\"write this response in hinglish, pointwise, and in a friendly tone\")])\n",
        "print(f\"\\n\\n ------------------ {final_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgeGPexgbMHz"
      },
      "source": [
        "### Create the agent using LangGraph now (using the above same tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "oYmX98hxbR2T"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Note that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\n",
        "react_agent_executor = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools,\n",
        "    prompt=\"You are a helpful assistant. Use tools when needed.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Yom0Pw8zbufx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the search tool now: params i got - > query:weather in New Delhi\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the current weather in New Delhi?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  searchtool (db150aac-fc4e-4f00-81b2-4d0254e750d2)\n",
            " Call ID: db150aac-fc4e-4f00-81b2-4d0254e750d2\n",
            "  Args:\n",
            "    query: weather in New Delhi\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: searchtool\n",
            "\n",
            "{'query': 'weather in New Delhi', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752324285, 'localtime': '2025-07-12 18:14'}, 'current': {'last_updated_epoch': 1752323400, 'last_updated': '2025-07-12 18:00', 'temp_c': 37.5, 'temp_f': 99.5, 'is_day': 1, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 177, 'wind_dir': 'S', 'pressure_mb': 998.0, 'pressure_in': 29.48, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 35, 'cloud': 30, 'feelslike_c': 41.0, 'feelslike_f': 105.8, 'windchill_c': 37.5, 'windchill_f': 99.5, 'heatindex_c': 41.0, 'heatindex_f': 105.8, 'dewpoint_c': 19.3, 'dewpoint_f': 66.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.1, 'gust_mph': 4.5, 'gust_kph': 7.2}}\", 'score': 0.9983051, 'raw_content': None}, {'url': 'https://www.msn.com/en-in/news/other/new-delhi-weather-update-heat-and-rain-expected-on-july-12-2025/ar-AA1IrGdA', 'title': 'New Delhi weather update: Heat and rain expected on July 12, 2025', 'content': 'New Delhi anticipates a warm and humid July 12, with temperatures peaking at 37.3°C and an 85% chance of patchy rain, offering evening', 'score': 0.96804774, 'raw_content': None}], 'response_time': 1.0}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The weather in New Delhi is partly cloudy with a temperature of 37.5°C (99.5°F). It feels like 41.0°C (105.8°F). There is a 30% cloud cover, with wind blowing from the South at 6.1 km/h. There is a high chance of patchy rain in the evening.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is the current weather in New Delhi?', additional_kwargs={}, response_metadata={}, id='d4fffe19-741b-4b4c-829d-995cf0a483f9'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'searchtool', 'arguments': '{\"query\": \"weather in New Delhi\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--9a7c9a14-e934-4b04-a89f-a5286285c061-0', tool_calls=[{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': 'db150aac-fc4e-4f00-81b2-4d0254e750d2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 39, 'output_tokens': 7, 'total_tokens': 46, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='{\\'query\\': \\'weather in New Delhi\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Weather in New Delhi\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'New Delhi\\', \\'region\\': \\'Delhi\\', \\'country\\': \\'India\\', \\'lat\\': 28.6, \\'lon\\': 77.2, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1752324285, \\'localtime\\': \\'2025-07-12 18:14\\'}, \\'current\\': {\\'last_updated_epoch\\': 1752323400, \\'last_updated\\': \\'2025-07-12 18:00\\', \\'temp_c\\': 37.5, \\'temp_f\\': 99.5, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly Cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 3.8, \\'wind_kph\\': 6.1, \\'wind_degree\\': 177, \\'wind_dir\\': \\'S\\', \\'pressure_mb\\': 998.0, \\'pressure_in\\': 29.48, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 35, \\'cloud\\': 30, \\'feelslike_c\\': 41.0, \\'feelslike_f\\': 105.8, \\'windchill_c\\': 37.5, \\'windchill_f\\': 99.5, \\'heatindex_c\\': 41.0, \\'heatindex_f\\': 105.8, \\'dewpoint_c\\': 19.3, \\'dewpoint_f\\': 66.7, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.1, \\'gust_mph\\': 4.5, \\'gust_kph\\': 7.2}}\", \\'score\\': 0.9983051, \\'raw_content\\': None}, {\\'url\\': \\'https://www.msn.com/en-in/news/other/new-delhi-weather-update-heat-and-rain-expected-on-july-12-2025/ar-AA1IrGdA\\', \\'title\\': \\'New Delhi weather update: Heat and rain expected on July 12, 2025\\', \\'content\\': \\'New Delhi anticipates a warm and humid July 12, with temperatures peaking at 37.3°C and an 85% chance of patchy rain, offering evening\\', \\'score\\': 0.96804774, \\'raw_content\\': None}], \\'response_time\\': 1.0}', name='searchtool', id='ec0a846c-a634-4919-b50d-1ab80f24e860', tool_call_id='db150aac-fc4e-4f00-81b2-4d0254e750d2'),\n",
              "  AIMessage(content='The weather in New Delhi is partly cloudy with a temperature of 37.5°C (99.5°F). It feels like 41.0°C (105.8°F). There is a 30% cloud cover, with wind blowing from the South at 6.1 km/h. There is a high chance of patchy rain in the evening.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--1bb9e3e4-b53e-4b85-849b-dd24743390f2-0', usage_metadata={'input_tokens': 738, 'output_tokens': 83, 'total_tokens': 821, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now using a relevant input prompt\n",
        "input_message = {\"role\": \"user\", \"content\": \"What is the current weather in New Delhi?\"}\n",
        "response = react_agent_executor.invoke({\"messages\": [input_message]})\n",
        "\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26PooOTljqcF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLEjIviFjqZk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "A38TN2VrjqWV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The weather in New Delhi is partly cloudy with a temperature of 37.5°C (99.5°F). It feels like 41.0°C (105.8°F). There is a 35% humidity and a light wind of 6.1 km/h from the south. There is a chance of patchy rain in the evening.\n"
          ]
        }
      ],
      "source": [
        "# WORKING CODE !!!\n",
        "\n",
        "# 1️⃣ Imports & setup\n",
        "import os, getpass\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# 2️⃣ API keys\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# 3️⃣ Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# 4️⃣ TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=2)\n",
        "\n",
        "# 5️⃣ Tool definition (match `query` signature)\n",
        "@tool\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search the web for `query`.\"\"\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "# 6️⃣ Create ReAct agent (auto .bind_tools under the hood)\n",
        "react_agent = create_react_agent(model=model, tools=tools)\n",
        "\n",
        "# 7️⃣ Invoke and print\n",
        "resp = react_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the current weather in New Delhi?\"}]\n",
        "})\n",
        "print(resp[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "EmUjJbATj6ft"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Btbm-t-xj6Fu"
      },
      "outputs": [],
      "source": [
        "## Tool 1: search_web\n",
        "\n",
        "# Pydantic schema for search_web inputs\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int\n",
        "\n",
        "# Tool definition using Pydantic\n",
        "@tool\n",
        "def search_web(input_data: WebSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search the web with a query and number of results.\n",
        "    \"\"\"\n",
        "    # Perform search\n",
        "    result = search_instance.invoke(input_data.query, k=input_data.num_results)\n",
        "    # Return stringified result\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "c8kpgldRlQ0r"
      },
      "outputs": [],
      "source": [
        "## Tool 2: search_weather\n",
        "\n",
        "# Pydantic schema for weather search inputs\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str  # e.g., \"Celsius\" or \"Fahrenheit\"\n",
        "\n",
        "@tool\n",
        "def search_weather(input_data: WeatherSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search weather information for a city.\n",
        "    \"\"\"\n",
        "    query = f\"current weather in {input_data.city} in {input_data.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "2kDYfWNMlYRp"
      },
      "outputs": [],
      "source": [
        "## Tool 3 : search_news\n",
        "\n",
        "# Pydantic schema for news search inputs\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "@tool\n",
        "def search_news(input_data: NewsSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search recent news headlines for a topic in a specific region.\n",
        "    \"\"\"\n",
        "    query = f\"latest news about {input_data.topic} in {input_data.region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "wJN3R72nlaQg"
      },
      "outputs": [],
      "source": [
        "## Register Tools\n",
        "# All tools are collected here\n",
        "tools = [\n",
        "    search_web,\n",
        "    search_weather,\n",
        "    search_news\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Mt1x4uOhlaNi"
      },
      "outputs": [],
      "source": [
        "# Create ReAct agent with the model and tools\n",
        "react_agent_2 = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ZhnCqwUxm2xl"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "vKGR2PColaKG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "Latest news in India: According to the Indian Express, Mann is stepping up his attack on PM Modi after MEA rap. According to the Times of India, breaking news includes sports, business, entertainment, blogs and opinions from leading columnists.\n",
            "\n",
            "Weather in New Delhi: The weather is partly cloudy with a temperature of 37.5 degrees Celsius, feels like 41.0 degrees Celsius. The wind is blowing from the South at 6.1 km/h.\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Give me the latest news and weather in India, new delhi\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search_news (a028b2ff-24de-4f27-ac11-9c0fdb0b1c66)\n",
            " Call ID: a028b2ff-24de-4f27-ac11-9c0fdb0b1c66\n",
            "  Args:\n",
            "    input_data: {'region': 'India', 'topic': 'latest'}\n",
            "  search_weather (4ca0fa2c-d18a-4dec-8d86-815251467284)\n",
            " Call ID: 4ca0fa2c-d18a-4dec-8d86-815251467284\n",
            "  Args:\n",
            "    input_data: {'city': 'new delhi', 'unit': 'celsius'}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_news\n",
            "\n",
            "{'query': 'latest news about latest in India', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://indianexpress.com/', 'title': 'Latest News Today: Breaking News and Top Headlines from India ...', 'content': \"Latest News · After MEA rap, Mann steps up attack on PM Modi · Why wasn't Shubman Gill asked to leave field for treatment? 'Umpires have lost control' Mike\", 'score': 0.6711479, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/', 'title': 'Times of India: News - Breaking News, Latest News, India News ...', 'content': 'Breaking News in India: Read Latest News on Sports, Business, Entertainment, Blogs and Opinions from leading columnists. Times of India brings the Breaking', 'score': 0.66203266, 'raw_content': None}], 'response_time': 1.33}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_weather\n",
            "\n",
            "{'query': 'current weather in new delhi in celsius', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752324285, 'localtime': '2025-07-12 18:14'}, 'current': {'last_updated_epoch': 1752323400, 'last_updated': '2025-07-12 18:00', 'temp_c': 37.5, 'temp_f': 99.5, 'is_day': 1, 'condition': {'text': 'Partly Cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 3.8, 'wind_kph': 6.1, 'wind_degree': 177, 'wind_dir': 'S', 'pressure_mb': 998.0, 'pressure_in': 29.48, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 35, 'cloud': 30, 'feelslike_c': 41.0, 'feelslike_f': 105.8, 'windchill_c': 37.5, 'windchill_f': 99.5, 'heatindex_c': 41.0, 'heatindex_f': 105.8, 'dewpoint_c': 19.3, 'dewpoint_f': 66.7, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 0.1, 'gust_mph': 4.5, 'gust_kph': 7.2}}\", 'score': 0.9447893, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/weather/new-delhi-weather-forecast-today/110011', 'title': 'New Delhi Weather Forecast 12 Jul 2025 - Times of India', 'content': \"Today's Weather in New Delhi: In New Delhi today, the weather is expected to be Haze with a maximum temperature of 33°C and a minimum of 28°C. Sunrise in\", 'score': 0.94225764, 'raw_content': None}], 'response_time': 1.71}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Latest news in India: According to the Indian Express, Mann is stepping up his attack on PM Modi after MEA rap. According to the Times of India, breaking news includes sports, business, entertainment, blogs and opinions from leading columnists.\n",
            "\n",
            "Weather in New Delhi: The weather is partly cloudy with a temperature of 37.5 degrees Celsius, feels like 41.0 degrees Celsius. The wind is blowing from the South at 6.1 km/h.\n"
          ]
        }
      ],
      "source": [
        "# User query to trigger one of the tools\n",
        "resp = react_agent_2.invoke({\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Give me the latest news and weather in India, new delhi\"}\n",
        "    ]\n",
        "}\n",
        "  )\n",
        "pprint(len(resp[\"messages\"]))\n",
        "\n",
        "print(resp[\"messages\"][-1].content)\n",
        "# pprint(resp[\"messages\"][-2].content)\n",
        "\n",
        "\n",
        "for message in resp[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QU3BInglaH3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KIUMIngQJiu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsWZOAO2QJhF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-m8fBrUQJd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR-YbMAmQJbC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOkeQQ36QJX2",
        "outputId": "81665d91-ce5e-4096-ac9f-f34e5df5811e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing Basic ReAct Agent ===\n",
            "Number of messages: 5\n",
            "Final response: Latest News: According to Indian Express, Mann is stepping up attack on PM Modi after MEA rap. Also, there is a discussion on why Shubman Gill wasn't asked to leave field for treatment.\n",
            "Weather in New Delhi: The current weather in New Delhi is 37.5 degrees Celsius with partly cloudy conditions. The wind is blowing from the South at 6.1 km/h. It feels like 41.0 degrees Celsius.\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict\n",
        "from pprint import pprint\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# API keys setup\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=2)\n",
        "\n",
        "## Tool 1: search_web\n",
        "# Pydantic schema for search_web inputs\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int = 2  # Default value\n",
        "\n",
        "# Tool definition using Pydantic\n",
        "@tool\n",
        "def search_web(input_data: WebSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search the web with a query and number of results.\n",
        "    \"\"\"\n",
        "    # Note: TavilySearch uses max_results parameter, not k\n",
        "    search_temp = TavilySearch(max_results=input_data.num_results)\n",
        "    result = search_temp.invoke(input_data.query)\n",
        "    return str(result)\n",
        "\n",
        "## Tool 2: search_weather\n",
        "# Pydantic schema for weather search inputs\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str = \"Celsius\"  # Default value\n",
        "\n",
        "@tool\n",
        "def search_weather(input_data: WeatherSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search weather information for a city.\n",
        "    \"\"\"\n",
        "    query = f\"current weather in {input_data.city} in {input_data.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "## Tool 3: search_news\n",
        "# Pydantic schema for news search inputs\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "@tool\n",
        "def search_news(input_data: NewsSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search recent news headlines for a topic in a specific region.\n",
        "    \"\"\"\n",
        "    query = f\"latest news about {input_data.topic} in {input_data.region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "## Register Tools\n",
        "# All tools are collected here\n",
        "tools = [\n",
        "    search_web,\n",
        "    search_weather,\n",
        "    search_news\n",
        "]\n",
        "\n",
        "# Create ReAct agent with the model and tools\n",
        "react_agent = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "# Test the basic ReAct agent\n",
        "print(\"=== Testing Basic ReAct Agent ===\")\n",
        "resp = react_agent.invoke({\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Give me the latest news and weather in India, New Delhi\"}\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(f\"Number of messages: {len(resp['messages'])}\")\n",
        "print(f\"Final response: {resp['messages'][-1].content}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhG3vbnZQJVF",
        "outputId": "2637e361-8419-46d3-e009-eac4b43a3889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing Custom StateGraph Agent ===\n",
            "User Input: What's the weather like in New Delhi today?\n",
            "Agent Response: The weather in New Delhi is partly cloudy with a temperature of 37.5 degrees Celsius, but it feels like 41.0 degrees Celsius.\n",
            "\n",
            "=== Testing News Query ===\n",
            "User Input: Give me the latest technology news in India\n",
            "Agent Response: OK. Here's the latest technology news in India:\n",
            "\n",
            "*   Times of India is providing trending tech news, mobile phones, laptops, reviews, software updates.\n",
            "*   The Hindu reports that Google Gemini has a new feature that can turn photos into video clips. Also, TikTok faces a fresh European privacy investigation over China data transfers.\n"
          ]
        }
      ],
      "source": [
        "# ✅ Define State for Custom Agent using TypedDict\n",
        "class AgentState(TypedDict):\n",
        "    user_input: str\n",
        "    response: str\n",
        "\n",
        "# ✅ Wrap ReAct agent as node\n",
        "def run_react_agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"Run the ReAct agent and update state with response\"\"\"\n",
        "    # ReAct agent takes list of messages\n",
        "    result = react_agent.invoke({\n",
        "        \"messages\": [HumanMessage(content=state[\"user_input\"])]\n",
        "    })\n",
        "\n",
        "    # Update state with response\n",
        "    state[\"response\"] = result[\"messages\"][-1].content\n",
        "    return state\n",
        "\n",
        "# ✅ Create StateGraph\n",
        "def create_custom_agent():\n",
        "    \"\"\"Create a custom agent using StateGraph\"\"\"\n",
        "\n",
        "    # Create the graph\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add the ReAct agent node\n",
        "    workflow.add_node(\"react_agent\", run_react_agent)\n",
        "\n",
        "    # Define the flow\n",
        "    workflow.add_edge(START, \"react_agent\")\n",
        "    workflow.add_edge(\"react_agent\", END)\n",
        "\n",
        "    # Compile the graph\n",
        "    return workflow.compile()\n",
        "\n",
        "# ✅ Test the custom StateGraph agent\n",
        "print(\"\\n=== Testing Custom StateGraph Agent ===\")\n",
        "custom_agent = create_custom_agent()\n",
        "\n",
        "# Test with initial state\n",
        "initial_state = {\n",
        "    \"user_input\": \"What's the weather like in New Delhi today?\",\n",
        "    \"response\": \"\"\n",
        "}\n",
        "\n",
        "result = custom_agent.invoke(initial_state)\n",
        "print(f\"User Input: {result['user_input']}\")\n",
        "print(f\"Agent Response: {result['response']}\")\n",
        "\n",
        "# ✅ Another test with news query\n",
        "print(\"\\n=== Testing News Query ===\")\n",
        "news_state = {\n",
        "    \"user_input\": \"Give me the latest technology news in India\",\n",
        "    \"response\": \"\"\n",
        "}\n",
        "\n",
        "news_result = custom_agent.invoke(news_state)\n",
        "print(f\"User Input: {news_result['user_input']}\")\n",
        "print(f\"Agent Response: {news_result['response']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h5WOlZEYipw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmUp7SOMYimz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtdSVsYkYijz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMK4M8n_Yi64"
      },
      "source": [
        "### Complex langgraph workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPMSW8ZNYihP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J9m-CPAGMdt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDLhPrDqGMbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCAY6FTGGMXi",
        "outputId": "15279b65-419a-4ff2-acc1-bf1221aeba84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=======================🚀 TEST CASE 1 =======================\n",
            "Query: What's the weather like in Delhi and give me latest technology news?\n",
            "\n",
            "🔄 [2025-07-12T18:13:40.956844] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:40.956844] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: weather, Entities: {'city': 'Delhi', 'topic': 'technology'}\n",
            "\n",
            "🔄 [2025-07-12T18:13:40.956844] NODE: weather_node | STATUS: STARTED\n",
            "Received user data for weather search: city='Delhi' unit='Celsius' of type <class '__main__.WeatherSearchInput'>\n",
            "\n",
            "🔄 [2025-07-12T18:13:43.451679] NODE: weather_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved weather for Delhi\n",
            "\n",
            "🔄 [2025-07-12T18:13:43.452205] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:46.056624] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content=\"Okay, here's a concise summary of the weather information for Delhi:\\n\\n*   **Location:** Delhi, Ontario, Canada.\\n*   **Current Temperature:** 23.3°C (73.9°F).\\n*   **Condition:** Sunny.\\n*   **Wind:** 14.4 km/h from the South.\\n*   **Humidity:** 89%.\\n*   **Feels Like:** 25.4°C\\n*   **Forecast for July:** Expect temperatures between 30.5°C (87°F) and 37.8°C (100°F). Moderate rain is possible.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--c9a6afdd-7823-4876-93f8-31da6efc2ddd-0' usage_metadata={'input_tokens': 801, 'output_tokens': 144, 'total_tokens': 945, 'input_token_details': {'cache_read': 0}}\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Okay, here's a concise summary of the weather information for Delhi:\n",
            "\n",
            "*   **Location:** Delhi, Ontario, Canada.\n",
            "*   **Current Temperature:** 23.3°C (73.9°F).\n",
            "*   **Condition:** Sunny.\n",
            "*   **Wind:** 14.4 km/h from the South.\n",
            "*   **Humidity:** 89%.\n",
            "*   **Feels Like:** 25.4°C\n",
            "*   **Forecast for July:** Expect temperatures between 30.5°C (87°F) and 37.8°C (100°F). Moderate rain is possible.\n",
            "\n",
            "============================================================\n",
            "\n",
            "=======================🚀 TEST CASE 2 =======================\n",
            "Query: Search for information about latest model of xai, grok and its information\n",
            "\n",
            "🔄 [2025-07-12T18:13:46.058127] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:46.058127] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: search, Entities: {}\n",
            "\n",
            "🔄 [2025-07-12T18:13:46.058127] NODE: general_search_node | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:48.013745] NODE: general_search_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved search results for: Search for information about latest model of xai, grok and its information\n",
            "\n",
            "🔄 [2025-07-12T18:13:48.013745] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:49.108090] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content='Okay, here\\'s a concise summary of the information about Grok:\\n\\n*   **Grok is an AI chatbot** developed by Elon Musk\\'s xAI.\\n*   **xAI has unveiled an early preview of Grok-3**, their most advanced model to date.\\n*   **Grok-3 blends superior reasoning with extensive pretraining knowledge.**\\n*   **Grok was launched in 2023** as an alternative to other \"woke\" bots.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--3ebbe86d-f862-4f5d-a6b9-4b9235a02cb4-0' usage_metadata={'input_tokens': 265, 'output_tokens': 101, 'total_tokens': 366, 'input_token_details': {'cache_read': 0}}\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Okay, here's a concise summary of the information about Grok:\n",
            "\n",
            "*   **Grok is an AI chatbot** developed by Elon Musk's xAI.\n",
            "*   **xAI has unveiled an early preview of Grok-3**, their most advanced model to date.\n",
            "*   **Grok-3 blends superior reasoning with extensive pretraining knowledge.**\n",
            "*   **Grok was launched in 2023** as an alternative to other \"woke\" bots.\n",
            "\n",
            "============================================================\n",
            "\n",
            "=======================🚀 TEST CASE 3 =======================\n",
            "Query: Give me news related to latest IPOs in india\n",
            "\n",
            "🔄 [2025-07-12T18:13:49.109071] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:49.109071] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: news, Entities: {}\n",
            "\n",
            "🔄 [2025-07-12T18:13:49.110047] NODE: news_node | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:51.021797] NODE: news_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved news for general in India\n",
            "\n",
            "🔄 [2025-07-12T18:13:51.022771] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-12T18:13:52.110772] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content=\"Here's a concise summary of the news information:\\n\\n*   **Indian Army Agniveer Recruitment:** The Indian Army conducted the Agniveer 2025 recruitment exams, starting June 30, 2025.\\n*   **General Admits Losses:** General Anil Chauhan confirmed India experienced aerial losses during a recent conflict with Pakistan.\\n*   **Response to Pakistan:** General Chauhan stated that India will not tolerate terrorism or nuclear threats from Pakistan.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--d8396842-6cd6-441e-9d78-a591008fbd4d-0' usage_metadata={'input_tokens': 412, 'output_tokens': 97, 'total_tokens': 509, 'input_token_details': {'cache_read': 0}}\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Here's a concise summary of the news information:\n",
            "\n",
            "*   **Indian Army Agniveer Recruitment:** The Indian Army conducted the Agniveer 2025 recruitment exams, starting June 30, 2025.\n",
            "*   **General Admits Losses:** General Anil Chauhan confirmed India experienced aerial losses during a recent conflict with Pakistan.\n",
            "*   **Response to Pakistan:** General Chauhan stated that India will not tolerate terrorism or nuclear threats from Pakistan.\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict, List, Optional, Literal\n",
        "from pprint import pprint\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# API keys setup\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=3)\n",
        "\n",
        "# ===== PYDANTIC SCHEMAS =====\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int = 2\n",
        "\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str = \"Celsius\"\n",
        "\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "# ===== TOOLS =====\n",
        "@tool\n",
        "def search_web(query: str, num_results: int = 2) -> str:\n",
        "    \"\"\"Search the web with a query and number of results.\"\"\"\n",
        "    search_temp = TavilySearch(max_results=num_results)\n",
        "    result = search_temp.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "@tool\n",
        "def search_weather(usrdata:WeatherSearchInput) -> str:\n",
        "    \"\"\"Search weather information for a city.\"\"\"\n",
        "    print(f\"Received user data for weather search: {usrdata} of type {type(usrdata)}\")\n",
        "    # Use the Pydantic model to access city and unit\n",
        "    query = f\"current weather in {usrdata.city} in {usrdata.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "# def search_weather(city: str, unit: str = \"Celsius\") -> str:\n",
        "#     \"\"\"Search weather information for a city.\"\"\"\n",
        "#     query = f\"current weather in {city} in {unit}\"\n",
        "#     result = search_instance.invoke(query)\n",
        "#     return str(result)\n",
        "\n",
        "@tool\n",
        "def search_news(topic: str, region: str = \"India\") -> str:\n",
        "    \"\"\"Search recent news headlines for a topic in a specific region.\"\"\"\n",
        "    query = f\"latest news about {topic} in {region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "# ===== COMPLEX STATE DEFINITION =====\n",
        "class ComplexAgentState(TypedDict):\n",
        "    # Input\n",
        "    user_input: str\n",
        "\n",
        "    # Processing stages\n",
        "    intent: Optional[str]\n",
        "    entities: Optional[dict]\n",
        "\n",
        "    # Results from different nodes\n",
        "    weather_data: Optional[str]\n",
        "    news_data: Optional[str]\n",
        "    general_search_data: Optional[str]\n",
        "\n",
        "    # Error handling\n",
        "    errors: List[str]\n",
        "    retry_count: int\n",
        "\n",
        "    # Node execution tracking\n",
        "    execution_log: List[dict]\n",
        "\n",
        "    # Final output\n",
        "    final_response: str\n",
        "\n",
        "    # Control flow\n",
        "    next_action: Optional[str]\n",
        "\n",
        "# ===== UTILITY FUNCTIONS =====\n",
        "def log_execution(state: ComplexAgentState, node_name: str, status: str, details: str = \"\"):\n",
        "    \"\"\"Log node execution for debugging\"\"\"\n",
        "    timestamp = datetime.now().isoformat()\n",
        "    log_entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"node\": node_name,\n",
        "        \"status\": status,\n",
        "        \"details\": details\n",
        "    }\n",
        "\n",
        "    if \"execution_log\" not in state:\n",
        "        state[\"execution_log\"] = []\n",
        "\n",
        "    state[\"execution_log\"].append(log_entry)\n",
        "\n",
        "    # Pretty print for real-time monitoring\n",
        "    print(f\"\\n🔄 [{timestamp}] NODE: {node_name} | STATUS: {status}\")\n",
        "    if details:\n",
        "        print(f\"   📝 Details: {details}\")\n",
        "\n",
        "def pretty_print_state(state: ComplexAgentState, title: str):\n",
        "    \"\"\"Pretty print the current state\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"📊 {title}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    for key, value in state.items():\n",
        "        if key == \"execution_log\":\n",
        "            continue  # Skip execution log in state dump\n",
        "\n",
        "        if isinstance(value, str) and len(value) > 100:\n",
        "            print(f\"{key}: {value[:100]}...\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "# ===== NODE FUNCTIONS =====\n",
        "\n",
        "def intent_classifier(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Classify user intent and extract entities\"\"\"\n",
        "    log_execution(state, \"intent_classifier\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        user_input = state[\"user_input\"].lower()\n",
        "\n",
        "        # Simple intent classification\n",
        "        if \"weather\" in user_input:\n",
        "            state[\"intent\"] = \"weather\"\n",
        "        elif \"news\" in user_input:\n",
        "            state[\"intent\"] = \"news\"\n",
        "        elif any(word in user_input for word in [\"search\", \"find\", \"look\"]):\n",
        "            state[\"intent\"] = \"search\"\n",
        "        else:\n",
        "            state[\"intent\"] = \"general\"\n",
        "\n",
        "        # Extract entities (simple keyword extraction)\n",
        "        entities = {}\n",
        "\n",
        "        # Extract city names (simple approach)\n",
        "        cities = [\"delhi\", \"mumbai\", \"bangalore\", \"chennai\", \"kolkata\", \"hyderabad\"]\n",
        "        for city in cities:\n",
        "            if city in user_input:\n",
        "                entities[\"city\"] = city.title()\n",
        "                break\n",
        "\n",
        "        # Extract topics\n",
        "        if \"technology\" in user_input or \"tech\" in user_input:\n",
        "            entities[\"topic\"] = \"technology\"\n",
        "        elif \"sports\" in user_input:\n",
        "            entities[\"topic\"] = \"sports\"\n",
        "        elif \"politics\" in user_input:\n",
        "            entities[\"topic\"] = \"politics\"\n",
        "\n",
        "        state[\"entities\"] = entities\n",
        "\n",
        "        log_execution(state, \"intent_classifier\", \"SUCCESS\",\n",
        "                     f\"Intent: {state['intent']}, Entities: {entities}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Intent classification failed: {str(e)}\")\n",
        "        log_execution(state, \"intent_classifier\", \"ERROR\", str(e))\n",
        "        return state\n",
        "\n",
        "def weather_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle weather-related queries\"\"\"\n",
        "    log_execution(state, \"weather_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        entities = state.get(\"entities\", {})\n",
        "        city = entities.get(\"city\", \"New Delhi\")  # Default city\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_weather.invoke({\"usrdata\": {\"city\": \"Delhi\", \"unit\": \"Celsius\"}})\n",
        "\n",
        "        state[\"weather_data\"] = result\n",
        "        log_execution(state, \"weather_node\", \"SUCCESS\", f\"Retrieved weather for {city}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Weather search failed: {str(e)}\")\n",
        "        log_execution(state, \"weather_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def news_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle news-related queries\"\"\"\n",
        "    log_execution(state, \"news_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        entities = state.get(\"entities\", {})\n",
        "        topic = entities.get(\"topic\", \"general\")\n",
        "        region = entities.get(\"city\", \"India\")\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_news.invoke({\"topic\": topic, \"region\": region})\n",
        "\n",
        "        state[\"news_data\"] = result\n",
        "        log_execution(state, \"news_node\", \"SUCCESS\", f\"Retrieved news for {topic} in {region}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"News search failed: {str(e)}\")\n",
        "        log_execution(state, \"news_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def general_search_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle general search queries\"\"\"\n",
        "    log_execution(state, \"general_search_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        query = state[\"user_input\"]\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_web.invoke({\"query\": query, \"num_results\": 3})\n",
        "\n",
        "        state[\"general_search_data\"] = result\n",
        "        log_execution(state, \"general_search_node\", \"SUCCESS\", f\"Retrieved search results for: {query}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"General search failed: {str(e)}\")\n",
        "        log_execution(state, \"general_search_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def error_handler_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle errors and decide on retries\"\"\"\n",
        "    log_execution(state, \"error_handler_node\", \"STARTED\")\n",
        "\n",
        "    retry_count = state.get(\"retry_count\", 0)\n",
        "\n",
        "    if retry_count < 2:  # Max 2 retries\n",
        "        log_execution(state, \"error_handler_node\", \"RETRY\", f\"Retry attempt {retry_count + 1}\")\n",
        "        state[\"next_action\"] = \"retry\"\n",
        "    else:\n",
        "        log_execution(state, \"error_handler_node\", \"GIVE_UP\", \"Max retries reached\")\n",
        "        state[\"next_action\"] = \"finalize\"\n",
        "\n",
        "    return state\n",
        "\n",
        "def response_synthesizer(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Synthesize final response from all collected data\"\"\"\n",
        "    log_execution(state, \"response_synthesizer\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        response_parts = []\n",
        "\n",
        "        # Add weather data if available\n",
        "        if state.get(\"weather_data\"):\n",
        "            response_parts.append(f\"🌤️ Weather Information:\\n{state['weather_data']}\")\n",
        "\n",
        "        # Add news data if available\n",
        "        if state.get(\"news_data\"):\n",
        "            response_parts.append(f\"📰 News Information:\\n{state['news_data']}\")\n",
        "\n",
        "        # Add general search data if available\n",
        "        if state.get(\"general_search_data\"):\n",
        "            response_parts.append(f\"🔍 Search Results:\\n{state['general_search_data']}\")\n",
        "\n",
        "        # Handle errors\n",
        "        if state.get(\"errors\"):\n",
        "            response_parts.append(f\"⚠️ Errors encountered:\\n\" + \"\\n\".join(state[\"errors\"]))\n",
        "\n",
        "        # Create final response\n",
        "        if response_parts:\n",
        "            final_response = \"\\n\\n\".join(response_parts)\n",
        "        else:\n",
        "            final_response = \"I apologize, but I couldn't retrieve any information for your query.\"\n",
        "\n",
        "        final_response = model.invoke([{\"role\": \"assistant\", \"content\": final_response},\n",
        "                      {\"role\": \"user\", \"content\": \"Organize this information into a concise pointwise response.\"},\n",
        "                      ])\n",
        "\n",
        "        state[\"final_response\"] = final_response.content\n",
        "        log_execution(state, \"response_synthesizer\", \"SUCCESS\", \"Final response created\")\n",
        "        print(f\"Final Response in synthesizer: {final_response}\")\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Response synthesis failed: {str(e)}\")\n",
        "        log_execution(state, \"response_synthesizer\", \"ERROR\", str(e))\n",
        "        state[\"final_response\"] = \"An error occurred while processing your request.\"\n",
        "        return state\n",
        "\n",
        "# ===== ROUTING FUNCTIONS =====\n",
        "\n",
        "def should_get_weather(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should get weather data\"\"\"\n",
        "    return state.get(\"intent\") in [\"weather\", \"general\"] and not state.get(\"weather_data\")\n",
        "\n",
        "def should_get_news(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should get news data\"\"\"\n",
        "    return state.get(\"intent\") in [\"news\", \"general\"] and not state.get(\"news_data\")\n",
        "\n",
        "def should_do_general_search(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should do general search\"\"\"\n",
        "    return state.get(\"intent\") == \"search\" and not state.get(\"general_search_data\")\n",
        "\n",
        "def should_handle_error(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should handle errors\"\"\"\n",
        "    return len(state.get(\"errors\", [])) > 0 and state.get(\"retry_count\", 0) < 2\n",
        "\n",
        "def route_after_classification(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after intent classification\"\"\"\n",
        "    if should_handle_error(state):\n",
        "        return \"handle_error\"\n",
        "    elif should_get_weather(state):\n",
        "        return \"weather\"\n",
        "    elif should_get_news(state):\n",
        "        return \"news\"\n",
        "    elif should_do_general_search(state):\n",
        "        return \"general_search\"\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "def route_after_data_collection(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after data collection nodes\"\"\"\n",
        "    if should_handle_error(state):\n",
        "        return \"handle_error\"\n",
        "    elif should_get_weather(state):\n",
        "        return \"weather\"\n",
        "    elif should_get_news(state):\n",
        "        return \"news\"\n",
        "    elif should_do_general_search(state):\n",
        "        return \"general_search\"\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "def route_after_error_handler(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after error handling\"\"\"\n",
        "    if state.get(\"next_action\") == \"retry\":\n",
        "        return route_after_classification(state)\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "# ===== CREATE COMPLEX WORKFLOW =====\n",
        "\n",
        "def create_complex_workflow():\n",
        "    \"\"\"Create a complex workflow with multiple nodes and error handling\"\"\"\n",
        "\n",
        "    workflow = StateGraph(ComplexAgentState)\n",
        "\n",
        "    # Add all nodes\n",
        "    workflow.add_node(\"classifier\", intent_classifier)\n",
        "    workflow.add_node(\"weather\", weather_node)\n",
        "    workflow.add_node(\"news\", news_node)\n",
        "    workflow.add_node(\"general_search\", general_search_node)\n",
        "    workflow.add_node(\"handle_error\", error_handler_node)\n",
        "    workflow.add_node(\"synthesizer\", response_synthesizer)\n",
        "\n",
        "    # Define edges\n",
        "    workflow.add_edge(START, \"classifier\")\n",
        "\n",
        "    # Conditional edges from classifier\n",
        "    workflow.add_conditional_edges(\n",
        "        \"classifier\",\n",
        "        route_after_classification,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Conditional edges from data collection nodes\n",
        "    workflow.add_conditional_edges(\n",
        "        \"weather\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"news\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"general_search\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Error handler routing\n",
        "    workflow.add_conditional_edges(\n",
        "        \"handle_error\",\n",
        "        route_after_error_handler,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # End at synthesizer\n",
        "    workflow.add_edge(\"synthesizer\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# ===== TEST THE COMPLEX WORKFLOW =====\n",
        "\n",
        "def test_complex_workflow():\n",
        "    \"\"\"Test the complex workflow with different queries\"\"\"\n",
        "\n",
        "    # Create the workflow\n",
        "    complex_agent = create_complex_workflow()\n",
        "\n",
        "    # Test cases\n",
        "    test_cases = [\n",
        "        \"What's the weather like in Delhi and give me latest technology news?\",\n",
        "        \"Search for information about latest model of xai, grok and its information\",\n",
        "        \"Give me news related to latest IPOs in india\",\n",
        "    ]\n",
        "\n",
        "    for i, query in enumerate(test_cases, 1):\n",
        "        print(f\"\\n{'🚀 TEST CASE ' + str(i) + ' ':=^60}\")\n",
        "        print(f\"Query: {query}\")\n",
        "\n",
        "        # Create initial state\n",
        "        initial_state = {\n",
        "            \"user_input\": query,\n",
        "            \"intent\": None,\n",
        "            \"entities\": None,\n",
        "            \"weather_data\": None,\n",
        "            \"news_data\": None,\n",
        "            \"general_search_data\": None,\n",
        "            \"errors\": [],\n",
        "            \"retry_count\": 0,\n",
        "            \"execution_log\": [],\n",
        "            \"final_response\": \"\",\n",
        "            \"next_action\": None\n",
        "        }\n",
        "\n",
        "        # Run the workflow\n",
        "        result = complex_agent.invoke(initial_state)\n",
        "\n",
        "        # Show final result\n",
        "        print(f\"\\n{'📋 FINAL RESULT ':=^60}\")\n",
        "        print(result[\"final_response\"])\n",
        "\n",
        "        # # Show execution log\n",
        "        # print(f\"\\n{'📊 EXECUTION LOG ':=^60}\")\n",
        "        # for log_entry in result[\"execution_log\"]:\n",
        "        #     print(f\"[{log_entry['timestamp']}] {log_entry['node']} - {log_entry['status']}\")\n",
        "        #     if log_entry['details']:\n",
        "        #         print(f\"   {log_entry['details']}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Run the test\n",
        "if __name__ == \"__main__\":\n",
        "    test_complex_workflow()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
