{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gUR8bNFEwLUW",
        "outputId": "57476149-93c8-47b4-a31c-779a889cc6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain[google-genai] in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (6.0.1)\n",
            "Requirement already satisfied: langchain-google-genai in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain[google-genai]) (2.1.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (4.13.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain[google-genai]) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3,>=2->langchain[google-genai]) (2024.2.2)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain[google-genai]) (3.1.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (3.10.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langsmith>=0.1.17->langchain[google-genai]) (0.23.0)\n",
            "Requirement already satisfied: anyio in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[google-genai]) (1.3.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai->langchain[google-genai])\n",
            "  Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (2.39.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.29.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->langchain[google-genai]) (0.6.1)\n",
            "Using cached google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "Successfully installed google-ai-generativelanguage-0.6.18\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install \"langchain[google-genai]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0tua7wH03Qsy",
        "outputId": "b73487dc-35b5-4f6a-ca40-5473d304a489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in d:\\pyinstallfolder\\py312\\lib\\site-packages (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# !pip install langchain-huggingface\n",
        "%pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7RxAQZvdou",
        "outputId": "8b5b4398-6d82-4ad9-a51b-e29b667e39d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv(r\"D:\\py_prac\\langchain-prac\\.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WQJONHz2z7aJ"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.5-pro\", model_provider=\"google_genai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eYaA78e0Esd",
        "outputId": "bfbcbb89-fb66-4c4d-9e8e-2e40eba67cc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'lc': 1,\n",
              " 'type': 'constructor',\n",
              " 'id': ['langchain', 'schema', 'messages', 'AIMessage'],\n",
              " 'kwargs': {'content': 'I am a large language model, trained by Google.',\n",
              "  'response_metadata': {'prompt_feedback': {'block_reason': 0,\n",
              "    'safety_ratings': []},\n",
              "   'finish_reason': 'STOP',\n",
              "   'model_name': 'gemini-2.5-pro',\n",
              "   'safety_ratings': []},\n",
              "  'type': 'ai',\n",
              "  'id': 'run--321f85cf-896f-4bf5-8469-b6f61cbc7943-0',\n",
              "  'usage_metadata': {'input_tokens': 7,\n",
              "   'output_tokens': 1198,\n",
              "   'total_tokens': 1205,\n",
              "   'input_token_details': {'cache_read': 0},\n",
              "   'output_token_details': {'reasoning': 1187}},\n",
              "  'tool_calls': [],\n",
              "  'invalid_tool_calls': []}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_resp = model.invoke(\"who are you, which model\")\n",
        "model_resp.to_json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4daoKuQqBrX3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOZv-3UWBr1P",
        "outputId": "b1008af1-35b8-4bad-ce6e-c429330b5da7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Translation: नमस्ते. Example: नमस्ते! आप कैसे हैं?'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into hindi. also add an example of the translation in a sentence. Do not use any other language in the response. Use the format: 'Translation: <translated text>. Example: <example sentence in hindi>'.\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "resp = model.invoke(messages)\n",
        "resp.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "cPtXzrQUBzEP",
        "outputId": "64691476-bb1c-436d-e5d8-727fb81831d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bzt_8cjfB2l_",
        "outputId": "299b64e1-bed0-48bc-a385-d0a5ba140b96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__add__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__class_vars__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_pydantic_core_schema__',\n",
              " '__get_pydantic_json_schema__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__pydantic_complete__',\n",
              " '__pydantic_computed_fields__',\n",
              " '__pydantic_core_schema__',\n",
              " '__pydantic_custom_init__',\n",
              " '__pydantic_decorators__',\n",
              " '__pydantic_extra__',\n",
              " '__pydantic_fields__',\n",
              " '__pydantic_fields_set__',\n",
              " '__pydantic_generic_metadata__',\n",
              " '__pydantic_init_subclass__',\n",
              " '__pydantic_parent_namespace__',\n",
              " '__pydantic_post_init__',\n",
              " '__pydantic_private__',\n",
              " '__pydantic_root_model__',\n",
              " '__pydantic_serializer__',\n",
              " '__pydantic_setattr_handlers__',\n",
              " '__pydantic_validator__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__replace__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_recursion__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_backwards_compat_tool_calls',\n",
              " '_calculate_keys',\n",
              " '_copy_and_set_values',\n",
              " '_get_value',\n",
              " '_iter',\n",
              " '_setattr_handler',\n",
              " 'additional_kwargs',\n",
              " 'construct',\n",
              " 'content',\n",
              " 'copy',\n",
              " 'dict',\n",
              " 'example',\n",
              " 'from_orm',\n",
              " 'get_lc_namespace',\n",
              " 'id',\n",
              " 'invalid_tool_calls',\n",
              " 'is_lc_serializable',\n",
              " 'json',\n",
              " 'lc_attributes',\n",
              " 'lc_id',\n",
              " 'lc_secrets',\n",
              " 'model_computed_fields',\n",
              " 'model_config',\n",
              " 'model_construct',\n",
              " 'model_copy',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_extra',\n",
              " 'model_fields',\n",
              " 'model_fields_set',\n",
              " 'model_json_schema',\n",
              " 'model_parametrized_name',\n",
              " 'model_post_init',\n",
              " 'model_rebuild',\n",
              " 'model_validate',\n",
              " 'model_validate_json',\n",
              " 'model_validate_strings',\n",
              " 'name',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'pretty_print',\n",
              " 'pretty_repr',\n",
              " 'response_metadata',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'text',\n",
              " 'to_json',\n",
              " 'to_json_not_implemented',\n",
              " 'tool_calls',\n",
              " 'type',\n",
              " 'update_forward_refs',\n",
              " 'usage_metadata',\n",
              " 'validate']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(resp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEnp8ZXwB8j7",
        "outputId": "d8303541-f1a1-4b34-c9a2-6639b78763b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Translation: नमस्ते. Example: नमस्ते! आप कैसे हैं?\n"
          ]
        }
      ],
      "source": [
        "resp.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tNuTWsJCOdm",
        "outputId": "a7d1e636-11b9-439e-9c8a-732af7834739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Translation: नमस्ते। Example: नमस्ते! आप कैसे हैं?<..>"
          ]
        }
      ],
      "source": [
        "for token in model.stream(messages):\n",
        "    print(token.content, end=\"<..>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Xdb6u3LWHH"
      },
      "source": [
        "Streaming with async"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6USit7dzCOT-",
        "outputId": "143712d1-aa72-4b81-b0b9-c4709bc9f602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(... Verse 1... )\n",
            "A goldfish in a bowl so clear,\n",
            "Dreamed of stars, held...  them oh so dear.\n",
            "He wished upon a lunar gleam,\n",
            "For...  an escape from his watery dream.\n",
            "Then zoom! A rocket, built of kelp and sand,\n",
            "Lifted him high, towards the promised land.\n",
            "He...  floats among the craters, silent and white,\n",
            "A shimmering speck in the pale moonlight.\n",
            "His fins now dance in zero-G,\n",
            "No longer bound...  by gravity.\n",
            "He nibbles moon dust, a curious treat,\n",
            "A cosmic goldfish, bittersweet.\n",
            "He gazes back at Earth so blue,\n",
            "A tiny planet, shining anew.\n",
            "He's a pioneer, bold and bright,\n",
            "... A goldfish moon, bathed in silver light.\n",
            "... "
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize the chat model\n",
        "chatmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "\n",
        "# Use async directly at the top level in Jupyter, ignore the error or just wrap the api call in the async function and just await that function (without a new async loop)\n",
        "async for chunk in chatmodel.astream(\"Write me a 1 verse song about goldfish on the moon, of 150 words.\"):\n",
        "    print(chunk.content, end=\"... \", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il6E2nWvK2qC"
      },
      "source": [
        "OR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkJKPIiTKqtp",
        "outputId": "900d2956-a0cc-469a-a2fe-b1ba5057605c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(|Verse 1|)\n",
            "In a rocket built of bubblegum and dreams,\n",
            "A goldfish floats|, it brightly gleams.\n",
            "He's landed on the moon, a crater|ed sea,\n",
            "Of silent dust, for him and me.\n",
            "He nibbles space dust, thinks it's flakes of gold,\n",
            "A cosmic tale|, forever to be told.\n",
            "A goldfish on the moon, a shimmering sight,\n",
            "Bathing in the Earth's pale, lonely light.\n",
            "|"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# nest_asyncio.apply()  # Patch the running event loop\n",
        "\n",
        "async def main():\n",
        "    chatmodel = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
        "    async for chunk in chatmodel.astream(\"Write me a 1 verse song about goldfish on the moon\"):\n",
        "        print(chunk.content, end=\"|\", flush=True)\n",
        "\n",
        "# Works now in Colab/Jupyter\n",
        "await main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWH32B8lP5sY"
      },
      "source": [
        "ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWH-n6YvLZtq",
        "outputId": "1e35d01e-c52e-4f21-a864-2150a1f93371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "# prompt_template = ChatPromptTemplate.from_messages(\n",
        "#     [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        "# )\n",
        "prompt = prompt_template.invoke({\"language\": \"hindi\", \"text\": \"hi!\"})\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b9Nbu_gyLZq_",
        "outputId": "da0ce27d-addb-4e1d-eb21-a04627aca478"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__class_vars__',\n",
              " '__copy__',\n",
              " '__deepcopy__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__fields__',\n",
              " '__fields_set__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__get_pydantic_core_schema__',\n",
              " '__get_pydantic_json_schema__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__pretty__',\n",
              " '__private_attributes__',\n",
              " '__pydantic_complete__',\n",
              " '__pydantic_computed_fields__',\n",
              " '__pydantic_core_schema__',\n",
              " '__pydantic_custom_init__',\n",
              " '__pydantic_decorators__',\n",
              " '__pydantic_extra__',\n",
              " '__pydantic_fields__',\n",
              " '__pydantic_fields_set__',\n",
              " '__pydantic_generic_metadata__',\n",
              " '__pydantic_init_subclass__',\n",
              " '__pydantic_parent_namespace__',\n",
              " '__pydantic_post_init__',\n",
              " '__pydantic_private__',\n",
              " '__pydantic_root_model__',\n",
              " '__pydantic_serializer__',\n",
              " '__pydantic_setattr_handlers__',\n",
              " '__pydantic_validator__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__replace__',\n",
              " '__repr__',\n",
              " '__repr_args__',\n",
              " '__repr_name__',\n",
              " '__repr_recursion__',\n",
              " '__repr_str__',\n",
              " '__rich_repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__signature__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_calculate_keys',\n",
              " '_copy_and_set_values',\n",
              " '_get_value',\n",
              " '_iter',\n",
              " '_setattr_handler',\n",
              " 'construct',\n",
              " 'copy',\n",
              " 'dict',\n",
              " 'from_orm',\n",
              " 'get_lc_namespace',\n",
              " 'is_lc_serializable',\n",
              " 'json',\n",
              " 'lc_attributes',\n",
              " 'lc_id',\n",
              " 'lc_secrets',\n",
              " 'messages',\n",
              " 'model_computed_fields',\n",
              " 'model_config',\n",
              " 'model_construct',\n",
              " 'model_copy',\n",
              " 'model_dump',\n",
              " 'model_dump_json',\n",
              " 'model_extra',\n",
              " 'model_fields',\n",
              " 'model_fields_set',\n",
              " 'model_json_schema',\n",
              " 'model_parametrized_name',\n",
              " 'model_post_init',\n",
              " 'model_rebuild',\n",
              " 'model_validate',\n",
              " 'model_validate_json',\n",
              " 'model_validate_strings',\n",
              " 'parse_file',\n",
              " 'parse_obj',\n",
              " 'parse_raw',\n",
              " 'schema',\n",
              " 'schema_json',\n",
              " 'to_json',\n",
              " 'to_json_not_implemented',\n",
              " 'to_messages',\n",
              " 'to_string',\n",
              " 'update_forward_refs',\n",
              " 'validate']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU7aUZYdLZoG",
        "outputId": "53aa4fc5-4906-4693-e533-4633fbc7608d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content='Translate the following from English into hindi', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt.to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltfevCFXLZlb",
        "outputId": "ec92f265-0fc9-4505-c20d-e3a2da23e464"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "नमस्ते (Namaste)\n"
          ]
        }
      ],
      "source": [
        "response = model.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lQA1OcZCTECq",
        "outputId": "8d98c8b2-cbd6-4787-d6f3-a73155361bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in d:\\pyinstallfolder\\py312\\lib\\site-packages (0.8.5)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.39.0)\n",
            "Requirement already satisfied: protobuf in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\pyinstallfolder\\py312\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: colorama in d:\\pyinstallfolder\\py312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
            "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
            "Successfully installed google-ai-generativelanguage-0.6.15\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.7 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%pip install google-generativeai --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ApKYZrTD-9"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import time\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Upload file\n",
        "file = client.files.upload(file=r\"D:\\py_prac\\langchain-prac\\datasets\\CPlusPlusNotesForProfessionals.pdf\")\n",
        "while file.state.name == 'PROCESSING':\n",
        "    print(f\"File {file.name} is still processing...\")\n",
        "    # Wait for processing to complete\n",
        "    time.sleep(2)\n",
        "    file = client.files.get(name=file.name)\n",
        "\n",
        "# Create cache\n",
        "model = 'gemini-2.0-flash'\n",
        "cache = client.caches.create(\n",
        "    model=model,\n",
        "    config=types.CreateCachedContentConfig(\n",
        "        display_name='Cached Content',\n",
        "        system_instruction=(\n",
        "            \"You are an expert content analyzer, and your job is to answer the user's query based on the file you have access to.\"\n",
        "        ),\n",
        "        contents=[file],\n",
        "        ttl=\"3000s\",\n",
        "    )\n",
        ")\n",
        "\n",
        "# Query with LangChain\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model,\n",
        "    cached_content=cache.name,\n",
        ")\n",
        "message = HumanMessage(content=\"Summarize the main points of the content.\")\n",
        "airesponse = llm.invoke([message])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The document is a comprehensive C++ notes for professionals, covering a wide range of topics from basic syntax and data types to advanced concepts like templates, metaprogramming, concurrency, and design patterns. It provides detailed explanations, code examples, and comparisons between different C++ standards. It also includes information on build systems, debugging techniques, and undefined behaviors. The document appears to be compiled from Stack Overflow Documentation and is intended for educational purposes.'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airesponse.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I am sorry, but I cannot fulfill that request. Based on the OCR results, the document is about C++ not python.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke([HumanMessage(content=\"Tell me about the python related part in this pdf\")]).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3JCr5thUFyU",
        "outputId": "d529652a-531a-4d52-badc-2f779746801d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CachedContent(name='cachedContents/y0ik120w771yagntbecgfqt7ad9qc3150qfndkil', display_name='Cached Content', model='models/gemini-2.0-flash', create_time=datetime.datetime(2025, 7, 11, 1, 11, 52, 17143, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 7, 11, 1, 11, 52, 17143, tzinfo=TzInfo(UTC)), expire_time=datetime.datetime(2025, 7, 11, 1, 16, 51, 59740, tzinfo=TzInfo(UTC)), usage_metadata=CachedContentUsageMetadata(audio_duration_seconds=None, image_count=None, text_count=None, total_token_count=182693, video_duration_seconds=None))"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5S7iL7pTA_pw",
        "outputId": "30a34e8a-28cb-4c68-f0be-4d13c13d3e9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_aio',\n",
              " '_api_client',\n",
              " '_batches',\n",
              " '_caches',\n",
              " '_debug_config',\n",
              " '_files',\n",
              " '_get_api_client',\n",
              " '_models',\n",
              " '_operations',\n",
              " '_tokens',\n",
              " '_tunings',\n",
              " 'aio',\n",
              " 'auth_tokens',\n",
              " 'batches',\n",
              " 'caches',\n",
              " 'chats',\n",
              " 'files',\n",
              " 'models',\n",
              " 'operations',\n",
              " 'tunings',\n",
              " 'vertexai']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0VXDeohBDlX",
        "outputId": "3d5cb9ad-1008-43a5-efb8-e9c39fb0218a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<google.genai.caches.Caches at 0x7f8595d3d5d0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.caches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "osGiNj_jBYzC",
        "outputId": "abbfb306-aa0b-4ec1-f9c5-3b475e6ce8a8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'files/6q22rhyy1spc'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEYC9jeeBklC",
        "outputId": "9146a11e-9361-42de-c34e-47c1189f657e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CachedContent(\n",
              "  create_time=datetime.datetime(2025, 7, 9, 8, 30, 28, 100941, tzinfo=TzInfo(UTC)),\n",
              "  name='files/rvmpfysdfu0m',\n",
              "  update_time=datetime.datetime(2025, 7, 9, 8, 30, 28, 100941, tzinfo=TzInfo(UTC))\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "client.caches.get(name=\"files/rvmpfysdfu0m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U64EFXRRAl-O",
        "outputId": "935269d6-0095-4098-8be2-55c6ce333317"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ACTIVE'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file.state.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "HKDLslIKTD7N",
        "outputId": "99c3c662-16a7-4292-f7df-c95983572de6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: Union[str, list[Union[str, dict]]], **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "AIMessage is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model together standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 151);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(airesponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "3rYpWP5ksWzs",
        "outputId": "58b7f964-9684-420c-8985-4cbd943c7b41"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Here\\'s a summary of the document\\'s main points:\\n\\n*   **Hardware Security Modules (HSMs) as the Gold Standard:** The document begins by defining HSMs as physical devices providing a secure environment for cryptographic key management, emphasizing their role as a hardware Root of Trust (RoT). It highlights their internal architecture (secure processors, tamper-resistant storage, random number generators) and physical/logical defenses.\\n\\n*   **Demystifying \"Crypto Tokens\":** It clarifies the differences between HSMs and other technologies often referred to as \"crypto tokens,\" distinguishing between portable cryptographic tokens (USB tokens, smart cards) and blockchain crypto-tokens. It emphasizes that these are fundamentally different from HSMs in terms of purpose, architecture, and performance.\\n\\n*   **Blueprint for a Cloud-Native SoftHSM Service:** The document then shifts to the concept of a Software HSM (SoftHSM) as a cloud-native alternative, aiming to provide similar functionality without the physical appliance. It discusses the architecture of existing SoftHSMs like OpenDNSSEC\\'s, pointing out their inherent security limitations due to reliance on general-purpose operating systems.\\n\\n*   **Forging a Software Root of Trust with Trusted Execution Environments (TEEs):** It proposes using Trusted Execution Environments (TEEs), like Intel SGX or AMD SEV-SNP, to create a more secure SoftHSM by providing a hardware-enforced boundary in software.\\n\\n*   **Designing for a Multi-Tenant Cloud Environment:** The document addresses the challenges of offering a SoftHSM as a public cloud service, outlining architectural patterns for multi-tenancy and emphasizing the importance of cryptographic isolation and robust identity/access management.\\n\\n*   **Scalability and High Availability:** It emphasizes the need for a SoftHSM service to be scalable and resilient, advocating for stateless architecture and leveraging cloud-native services.\\n\\n*   **Implementation Strategy:** The document discusses the \"build vs. buy\" dilemma for components, recommending a hybrid approach that combines open standards with commercial, FIPS-validated cryptographic SDKs.\\n\\n*   **API and Standards Compliance:** It stresses the importance of adhering to established standards, particularly the PKCS#11 API, for interoperability.\\n\\n*   **Target Use Cases and Required Functionality:** It identifies key use cases for a SoftHSM service, including general-purpose key management, TLS/SSL offloading, digital signing, and blockchain/digital asset custody.\\n\\n*   **Governance, Risk, Compliance, and Best Practices:** The document concludes by addressing the non-technical aspects of running a cryptographic service, emphasizing the need for legal compliance, operational security, key management best practices, and insider threat mitigation. It also highlights the challenges of key management as a service (KaaS) and the importance of customer education.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airesponse.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8IdRl1vzYxi"
      },
      "source": [
        "## Agent using langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lk_sCcrrGwum",
        "outputId": "5996cd37-f9d7-43f5-8393-86c175dd1845"
      },
      "outputs": [],
      "source": [
        "%pip install -U langgraph langchain-tavily langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8KfVjPVWGwr6"
      },
      "outputs": [],
      "source": [
        "from langchain_tavily import TavilySearch\n",
        "from langchain.tools import tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5WSgB1PG0tBN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "  os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Enter API key for TAVILY_API_KEY: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sFXnvYSGwpF",
        "outputId": "237b43a1-c151-41d3-9a62-0e6be463edaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'query': 'What is the weather in New Delhi', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752203172, 'localtime': '2025-07-11 08:36'}, 'current': {'last_updated_epoch': 1752202800, 'last_updated': '2025-07-11 08:30', 'temp_c': 30.3, 'temp_f': 86.5, 'is_day': 1, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/day/143.png', 'code': 1030}, 'wind_mph': 3.4, 'wind_kph': 5.4, 'wind_degree': 118, 'wind_dir': 'ESE', 'pressure_mb': 1003.0, 'pressure_in': 29.62, 'precip_mm': 0.05, 'precip_in': 0.0, 'humidity': 75, 'cloud': 50, 'feelslike_c': 33.9, 'feelslike_f': 93.0, 'windchill_c': 31.0, 'windchill_f': 87.8, 'heatindex_c': 35.3, 'heatindex_f': 95.5, 'dewpoint_c': 22.6, 'dewpoint_f': 72.7, 'vis_km': 2.5, 'vis_miles': 1.0, 'uv': 2.9, 'gust_mph': 4.0, 'gust_kph': 6.5}}\", 'score': 0.9083549, 'raw_content': None}, {'url': 'https://world-weather.info/forecast/india/delhi/july-2025/', 'title': 'Weather in Delhi in July 2025', 'content': \"Weather in Delhi in July 2025 (Union Territory of Delhi) - Detailed Weather Forecast for a Month Weather World Weather in Delhi Weather in Delhi in July 2025 Delhi Weather Forecast for July 2025, is based on previous years' statistical data. +100°+90° +99°+88° +97°+88° +97°+88° +95°+86° +93°+84° +97°+88° +97°+88° +95°+86° +97°+88° +95°+84° +93°+86° +95°+88° +95°+86° +95°+86° +95°+88° +93°+84° +93°+84° +95°+86° +95°+84° +93°+84° +93°+86° +93°+84° +95°+86° +93°+84° +91°+82° +91°+84° +93°+84° +91°+82° +93°+84° +93°+84° Extended weather forecast in Delhi HourlyWeek10-Day14-Day30-DayYear Weather in large and nearby cities Weather in New Delhi+91° Panipat+93° Muzaffarnagar+95° Karnāl+95° Aligarh+95° Alwar+95° Mathura+95° Sahāranpur+93° Morādābād+95° Rohtak+93° Meerut+93° Okhla Industrial Development Area+88° Nāngloi Jāt+88° Ghaziabad+91° Noida+93° Faridabad+88° Gurgaon+88° Sonīpat+91° world's temperature today day day Weather forecast on your site Install Delhi+88°\", 'score': 0.882276, 'raw_content': None}], 'response_time': 1.87}\n"
          ]
        }
      ],
      "source": [
        "search = TavilySearch(max_results=2)\n",
        "search_results = search.invoke(\"What is the weather in New Delhi\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "# from pydantic import BaseModel\n",
        "\n",
        "# class SearchInput(BaseModel):\n",
        "#     query: str\n",
        "\n",
        "@tool\n",
        "def searchtool(query) -> str:\n",
        "    \"\"\"Search the web for recent information about anything you don't know.\"\"\"\n",
        "    print(f\"In the search tool now: params i got - > query:{query}\")\n",
        "    result = search.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "tools = [searchtool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NnkA8js3XG3Z"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HSehtt_KGwmN"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"Hi!\"\n",
        "response = model.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "response.text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rV3OE9X1GwiO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Message content: \n",
            "\n",
            "Tool calls: [{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': 'b567f5f5-f628-4890-877b-ee2d425b13cd', 'type': 'tool_call'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
        "\n",
        "model_plus_tools = model.bind_tools(tools)\n",
        "\n",
        "query = \"What is the weather in New Delhi?\"\n",
        "# response = model_plus_tools.invoke([{\"role\": \"user\", \"content\": query}])\n",
        "response = model_plus_tools.invoke([HumanMessage(content=query)])\n",
        "\n",
        "print(f\"Message content: {response.text()}\\n\")\n",
        "# here there is no response but as we can see that the tool is being MARKED TO BE called.\n",
        "print(f\"Tool calls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "EkLso4_fd21V"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'searchtool',\n",
              " 'args': {'query': 'weather in New Delhi'},\n",
              " 'id': 'b567f5f5-f628-4890-877b-ee2d425b13cd',\n",
              " 'type': 'tool_call'}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.tool_calls[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': 'b567f5f5-f628-4890-877b-ee2d425b13cd', 'type': 'tool_call'}\n",
            "args =  {'query': 'weather in New Delhi'}\n",
            "\n",
            "\n",
            " ------------------ Okay, dost! Here's the weather report for New Delhi, in Hinglish and pointwise, just like you asked!\n",
            "\n",
            "*   **Location:** New Delhi, bhai! (Delhi region, India)\n",
            "*   **Time:** 7:40 AM, 11th July 2025 (Asia/Kolkata time)\n",
            "*   **Temperature:** 27.3°C (81.1°F) - Thoda garam hai!\n",
            "*   **Condition:** \"Moderate or heavy rain with thunder\" - Baarish aur bijli dono ka scene hai! ⛈️\n",
            "*   **Wind:** 5.8 kph, east direction se aa rahi hai.\n",
            "*   **Humidity:** 94% - Chipchipi garmi rahegi!\n",
            "*   **Feels like:** 29.4°C (84.9°F) - Actually, it will feel hotter than the actual temperature.\n",
            "*   **Rainfall:** 0.02 mm - Light si baarish hai.\n",
            "*   **Visibility:** 2.5 km - Thoda dhundla dhundla dikhega.\n",
            "\n",
            "Stay safe and enjoy the weather, yaar! Chhatri leke nikalna! 😉\n"
          ]
        }
      ],
      "source": [
        "# Now to actually call the tool, we need to use the tool calls in the response.\n",
        "# Now we can call the tool with the tool call.\n",
        "tool_call = response.tool_calls[0]\n",
        "print(tool_call)\n",
        "print(\"args = \", tool_call[\"args\"])\n",
        "tool_response = search.invoke(tool_call[\"args\"])\n",
        "tool_response_content = tool_response[\"results\"][0]\n",
        "final_response = model.invoke([AIMessage(content=str(tool_response_content)), HumanMessage(content=\"write this response in hinglish, pointwise, and in a friendly tone\")])\n",
        "print(f\"\\n\\n ------------------ {final_response.content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgeGPexgbMHz"
      },
      "source": [
        "### Create the agent using LangGraph now (using the above same tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "oYmX98hxbR2T"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Note that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\n",
        "react_agent_executor = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools,\n",
        "    prompt=\"You are a helpful assistant. Use tools when needed.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yom0Pw8zbufx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the search tool now: params i got - > query:weather in New Delhi\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "What is the current weather in New Delhi?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  searchtool (8824723f-5a92-4b3c-8f7e-199a5988d923)\n",
            " Call ID: 8824723f-5a92-4b3c-8f7e-199a5988d923\n",
            "  Args:\n",
            "    query: weather in New Delhi\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: searchtool\n",
            "\n",
            "{'query': 'weather in New Delhi', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752199854, 'localtime': '2025-07-11 07:40'}, 'current': {'last_updated_epoch': 1752199200, 'last_updated': '2025-07-11 07:30', 'temp_c': 27.3, 'temp_f': 81.1, 'is_day': 1, 'condition': {'text': 'Moderate or heavy rain with thunder', 'icon': '//cdn.weatherapi.com/weather/64x64/day/389.png', 'code': 1276}, 'wind_mph': 3.6, 'wind_kph': 5.8, 'wind_degree': 95, 'wind_dir': 'E', 'pressure_mb': 1003.0, 'pressure_in': 29.62, 'precip_mm': 0.02, 'precip_in': 0.0, 'humidity': 94, 'cloud': 75, 'feelslike_c': 29.4, 'feelslike_f': 84.9, 'windchill_c': 29.7, 'windchill_f': 85.4, 'heatindex_c': 33.7, 'heatindex_f': 92.6, 'dewpoint_c': 22.9, 'dewpoint_f': 73.1, 'vis_km': 2.5, 'vis_miles': 1.0, 'uv': 1.1, 'gust_mph': 4.2, 'gust_kph': 6.8}}\", 'score': 0.9988514, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/weather/new-delhi-weather-forecast-today/110011', 'title': 'New Delhi Weather Forecast 11 Jul 2025 - The Times of India', 'content': \"Today's Weather in New Delhi: In New Delhi today, the weather is expected to be Mist with a maximum temperature of 30°C and a minimum of 26°C. Sunrise in\", 'score': 0.94956195, 'raw_content': None}], 'response_time': 1.15}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "The current weather in New Delhi is moderate or heavy rain with thunder. The temperature is 27.3°C, but it feels like 33.7°C due to the heat index. The wind is blowing from the east at 5.8 kph. Visibility is 2.5 km.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'messages': [HumanMessage(content='What is the current weather in New Delhi?', additional_kwargs={}, response_metadata={}, id='3b1de648-9184-4c7e-9f75-a7cf2a02af5a'),\n",
              "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'searchtool', 'arguments': '{\"query\": \"weather in New Delhi\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--95dfaab1-3e50-44eb-8863-de8a0a38bcf7-0', tool_calls=[{'name': 'searchtool', 'args': {'query': 'weather in New Delhi'}, 'id': '8824723f-5a92-4b3c-8f7e-199a5988d923', 'type': 'tool_call'}], usage_metadata={'input_tokens': 39, 'output_tokens': 7, 'total_tokens': 46, 'input_token_details': {'cache_read': 0}}),\n",
              "  ToolMessage(content='{\\'query\\': \\'weather in New Delhi\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Weather in New Delhi\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'New Delhi\\', \\'region\\': \\'Delhi\\', \\'country\\': \\'India\\', \\'lat\\': 28.6, \\'lon\\': 77.2, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1752199854, \\'localtime\\': \\'2025-07-11 07:40\\'}, \\'current\\': {\\'last_updated_epoch\\': 1752199200, \\'last_updated\\': \\'2025-07-11 07:30\\', \\'temp_c\\': 27.3, \\'temp_f\\': 81.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Moderate or heavy rain with thunder\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/389.png\\', \\'code\\': 1276}, \\'wind_mph\\': 3.6, \\'wind_kph\\': 5.8, \\'wind_degree\\': 95, \\'wind_dir\\': \\'E\\', \\'pressure_mb\\': 1003.0, \\'pressure_in\\': 29.62, \\'precip_mm\\': 0.02, \\'precip_in\\': 0.0, \\'humidity\\': 94, \\'cloud\\': 75, \\'feelslike_c\\': 29.4, \\'feelslike_f\\': 84.9, \\'windchill_c\\': 29.7, \\'windchill_f\\': 85.4, \\'heatindex_c\\': 33.7, \\'heatindex_f\\': 92.6, \\'dewpoint_c\\': 22.9, \\'dewpoint_f\\': 73.1, \\'vis_km\\': 2.5, \\'vis_miles\\': 1.0, \\'uv\\': 1.1, \\'gust_mph\\': 4.2, \\'gust_kph\\': 6.8}}\", \\'score\\': 0.9988514, \\'raw_content\\': None}, {\\'url\\': \\'https://timesofindia.indiatimes.com/weather/new-delhi-weather-forecast-today/110011\\', \\'title\\': \\'New Delhi Weather Forecast 11 Jul 2025 - The Times of India\\', \\'content\\': \"Today\\'s Weather in New Delhi: In New Delhi today, the weather is expected to be Mist with a maximum temperature of 30°C and a minimum of 26°C. Sunrise in\", \\'score\\': 0.94956195, \\'raw_content\\': None}], \\'response_time\\': 1.15}', name='searchtool', id='336e8e6f-b24e-4993-b2f0-6495ede543ec', tool_call_id='8824723f-5a92-4b3c-8f7e-199a5988d923'),\n",
              "  AIMessage(content='The current weather in New Delhi is moderate or heavy rain with thunder. The temperature is 27.3°C, but it feels like 33.7°C due to the heat index. The wind is blowing from the east at 5.8 kph. Visibility is 2.5 km.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ceb825b2-9158-4e67-8e7e-f2315ce9e956-0', usage_metadata={'input_tokens': 723, 'output_tokens': 65, 'total_tokens': 788, 'input_token_details': {'cache_read': 0}})]}"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now using a relevant input prompt\n",
        "input_message = {\"role\": \"user\", \"content\": \"What is the current weather in New Delhi?\"}\n",
        "response = react_agent_executor.invoke({\"messages\": [input_message]})\n",
        "\n",
        "for message in response[\"messages\"]:\n",
        "    message.pretty_print()\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26PooOTljqcF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLEjIviFjqZk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "A38TN2VrjqWV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current weather in New Delhi is moderate or heavy rain with thunder. The temperature is 27.3°C, but it feels like 33.7°C due to the heat index.\n"
          ]
        }
      ],
      "source": [
        "# WORKING CODE !!!\n",
        "\n",
        "# 1️⃣ Imports & setup\n",
        "import os, getpass\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# 2️⃣ API keys\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# 3️⃣ Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# 4️⃣ TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=2)\n",
        "\n",
        "# 5️⃣ Tool definition (match `query` signature)\n",
        "@tool\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search the web for `query`.\"\"\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "tools = [search]\n",
        "\n",
        "# 6️⃣ Create ReAct agent (auto .bind_tools under the hood)\n",
        "react_agent = create_react_agent(model=model, tools=tools)\n",
        "\n",
        "# 7️⃣ Invoke and print\n",
        "resp = react_agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What is the current weather in New Delhi?\"}]\n",
        "})\n",
        "print(resp[\"messages\"][-1].content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "EmUjJbATj6ft"
      },
      "outputs": [],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Btbm-t-xj6Fu"
      },
      "outputs": [],
      "source": [
        "## Tool 1: search_web\n",
        "\n",
        "# Pydantic schema for search_web inputs\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int\n",
        "\n",
        "# Tool definition using Pydantic\n",
        "@tool\n",
        "def search_web(input_data: WebSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search the web with a query and number of results.\n",
        "    \"\"\"\n",
        "    # Perform search\n",
        "    result = search_instance.invoke(input_data.query, k=input_data.num_results)\n",
        "    # Return stringified result\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "c8kpgldRlQ0r"
      },
      "outputs": [],
      "source": [
        "## Tool 2: search_weather\n",
        "\n",
        "# Pydantic schema for weather search inputs\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str  # e.g., \"Celsius\" or \"Fahrenheit\"\n",
        "\n",
        "@tool\n",
        "def search_weather(input_data: WeatherSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search weather information for a city.\n",
        "    \"\"\"\n",
        "    query = f\"current weather in {input_data.city} in {input_data.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2kDYfWNMlYRp"
      },
      "outputs": [],
      "source": [
        "## Tool 3 : search_news\n",
        "\n",
        "# Pydantic schema for news search inputs\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "@tool\n",
        "def search_news(input_data: NewsSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search recent news headlines for a topic in a specific region.\n",
        "    \"\"\"\n",
        "    query = f\"latest news about {input_data.topic} in {input_data.region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wJN3R72nlaQg"
      },
      "outputs": [],
      "source": [
        "## Register Tools\n",
        "# All tools are collected here\n",
        "tools = [\n",
        "    search_web,\n",
        "    search_weather,\n",
        "    search_news\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Mt1x4uOhlaNi"
      },
      "outputs": [],
      "source": [
        "# Create ReAct agent with the model and tools\n",
        "react_agent_2 = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ZhnCqwUxm2xl"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vKGR2PColaKG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "Here's the latest news and weather information for New Delhi, India:\n",
            "\n",
            "**News:**\n",
            "\n",
            "*   CNN: India news - breaking news, video and headlines and opinion\n",
            "*   The Indian Express: Axiom-4 mission: Shubhanshu Shukla to return to earth on July 14, says NASA. Ajmer's Rs 230 cr Ramsetu bridge closed after court takes note of structural damage.\n",
            "\n",
            "**Weather:**\n",
            "\n",
            "*   Temperature: 30.3°C\n",
            "*   Condition: Mist\n",
            "*   Wind: 5.4 kph ESE\n",
            "*   Humidity: 75%\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Give me the latest news and weather in India, new delhi\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  search_news (59539562-c608-495e-a9bc-cf63c31893f4)\n",
            " Call ID: 59539562-c608-495e-a9bc-cf63c31893f4\n",
            "  Args:\n",
            "    input_data: {'region': 'India', 'topic': 'latest'}\n",
            "  search_weather (0cf41eb2-a0c4-49c9-98c3-87d97608a830)\n",
            " Call ID: 0cf41eb2-a0c4-49c9-98c3-87d97608a830\n",
            "  Args:\n",
            "    input_data: {'city': 'new delhi', 'unit': 'celsius'}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_news\n",
            "\n",
            "{'query': 'latest news about latest in India', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://www.cnn.com/world/india', 'title': 'India news - breaking news, video and headlines and opinion | CNN', 'content': 'Latest news · A miracle in seat 11A: What we know about the sole survivor of Air India crash Vishwash Kumar Ramesh · How the Air India plane came crashing to', 'score': 0.5954225, 'raw_content': None}, {'url': 'https://indianexpress.com/section/india/', 'title': 'India News - The Indian Express', 'content': \"Axiom-4 mission: Shubhanshu Shukla to return to earth on July 14, says NASA · Ajmer's Rs 230 cr Ramsetu bridge closed after court takes note of structural damage.\", 'score': 0.49260366, 'raw_content': None}], 'response_time': 0.98}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: search_weather\n",
            "\n",
            "{'query': 'current weather in new delhi in celsius', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in New Delhi', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'New Delhi', 'region': 'Delhi', 'country': 'India', 'lat': 28.6, 'lon': 77.2, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1752203172, 'localtime': '2025-07-11 08:36'}, 'current': {'last_updated_epoch': 1752202800, 'last_updated': '2025-07-11 08:30', 'temp_c': 30.3, 'temp_f': 86.5, 'is_day': 1, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/day/143.png', 'code': 1030}, 'wind_mph': 3.4, 'wind_kph': 5.4, 'wind_degree': 118, 'wind_dir': 'ESE', 'pressure_mb': 1003.0, 'pressure_in': 29.62, 'precip_mm': 0.05, 'precip_in': 0.0, 'humidity': 75, 'cloud': 50, 'feelslike_c': 33.9, 'feelslike_f': 93.0, 'windchill_c': 31.0, 'windchill_f': 87.8, 'heatindex_c': 35.3, 'heatindex_f': 95.5, 'dewpoint_c': 22.6, 'dewpoint_f': 72.7, 'vis_km': 2.5, 'vis_miles': 1.0, 'uv': 2.9, 'gust_mph': 4.0, 'gust_kph': 6.5}}\", 'score': 0.936433, 'raw_content': None}, {'url': 'https://timesofindia.indiatimes.com/weather/new-delhi-weather-forecast-today/110011', 'title': 'New Delhi Weather Forecast 11 Jul 2025 - The Times of India', 'content': \"Today's Weather in New Delhi: In New Delhi today, the weather is expected to be Mist with a maximum temperature of 30°C and a minimum of 26°C. Sunrise in\", 'score': 0.9307171, 'raw_content': None}], 'response_time': 1.99}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here's the latest news and weather information for New Delhi, India:\n",
            "\n",
            "**News:**\n",
            "\n",
            "*   CNN: India news - breaking news, video and headlines and opinion\n",
            "*   The Indian Express: Axiom-4 mission: Shubhanshu Shukla to return to earth on July 14, says NASA. Ajmer's Rs 230 cr Ramsetu bridge closed after court takes note of structural damage.\n",
            "\n",
            "**Weather:**\n",
            "\n",
            "*   Temperature: 30.3°C\n",
            "*   Condition: Mist\n",
            "*   Wind: 5.4 kph ESE\n",
            "*   Humidity: 75%\n"
          ]
        }
      ],
      "source": [
        "# User query to trigger one of the tools\n",
        "resp = react_agent_2.invoke({\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Give me the latest news and weather in India, new delhi\"}\n",
        "    ]\n",
        "}\n",
        "  )\n",
        "pprint(len(resp[\"messages\"]))\n",
        "\n",
        "print(resp[\"messages\"][-1].content)\n",
        "# pprint(resp[\"messages\"][-2].content)\n",
        "\n",
        "\n",
        "for message in resp[\"messages\"]:\n",
        "    message.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QU3BInglaH3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KIUMIngQJiu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsWZOAO2QJhF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-m8fBrUQJd7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR-YbMAmQJbC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOkeQQ36QJX2",
        "outputId": "81665d91-ce5e-4096-ac9f-f34e5df5811e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Testing Basic ReAct Agent ===\n",
            "Number of messages: 5\n",
            "Final response: OK. Here's the latest news and weather information for you:\n",
            "\n",
            "**News:**\n",
            "\n",
            "*   CNN reports on India news, including a bridge collapse in Gujarat state that killed 9 people.\n",
            "*   The Indian Express reports that Shubhanshu Shukla is returning to earth on July 14 and that the Ramsetu bridge in Ajmer has been closed due to structural damage.\n",
            "\n",
            "**Weather in New Delhi:**\n",
            "\n",
            "*   The weather is currently mist.\n",
            "*   The temperature is 30.3°C, but it feels like 35.3°C due to the heat index.\n",
            "*   The wind is coming from the ESE at 5.4 km/h.\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict\n",
        "from pprint import pprint\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# API keys setup\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=2)\n",
        "\n",
        "## Tool 1: search_web\n",
        "# Pydantic schema for search_web inputs\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int = 2  # Default value\n",
        "\n",
        "# Tool definition using Pydantic\n",
        "@tool\n",
        "def search_web(input_data: WebSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search the web with a query and number of results.\n",
        "    \"\"\"\n",
        "    # Note: TavilySearch uses max_results parameter, not k\n",
        "    search_temp = TavilySearch(max_results=input_data.num_results)\n",
        "    result = search_temp.invoke(input_data.query)\n",
        "    return str(result)\n",
        "\n",
        "## Tool 2: search_weather\n",
        "# Pydantic schema for weather search inputs\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str = \"Celsius\"  # Default value\n",
        "\n",
        "@tool\n",
        "def search_weather(input_data: WeatherSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search weather information for a city.\n",
        "    \"\"\"\n",
        "    query = f\"current weather in {input_data.city} in {input_data.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "## Tool 3: search_news\n",
        "# Pydantic schema for news search inputs\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "@tool\n",
        "def search_news(input_data: NewsSearchInput) -> str:\n",
        "    \"\"\"\n",
        "    Search recent news headlines for a topic in a specific region.\n",
        "    \"\"\"\n",
        "    query = f\"latest news about {input_data.topic} in {input_data.region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "## Register Tools\n",
        "# All tools are collected here\n",
        "tools = [\n",
        "    search_web,\n",
        "    search_weather,\n",
        "    search_news\n",
        "]\n",
        "\n",
        "# Create ReAct agent with the model and tools\n",
        "react_agent = create_react_agent(\n",
        "    model=model,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "# Test the basic ReAct agent\n",
        "print(\"=== Testing Basic ReAct Agent ===\")\n",
        "resp = react_agent.invoke({\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Give me the latest news and weather in India, New Delhi\"}\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(f\"Number of messages: {len(resp['messages'])}\")\n",
        "print(f\"Final response: {resp['messages'][-1].content}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhG3vbnZQJVF",
        "outputId": "2637e361-8419-46d3-e009-eac4b43a3889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Testing Custom StateGraph Agent ===\n",
            "User Input: What's the weather like in New Delhi today?\n",
            "Agent Response: The weather in New Delhi today is Mist with a maximum temperature of 30°C and a minimum of 26°C.\n",
            "\n",
            "=== Testing News Query ===\n",
            "User Input: Give me the latest technology news in India\n",
            "Agent Response: OK. Here's the latest technology news in India: According to the Times of India, they provide the latest technology news and daily tech news updates, including trending tech news, mobile phones, laptops, reviews, and software updates. The Hindu also reports on technology news, with recent articles including \"PM Modi conferred with Namibia's highest civilian award,\" \"World's largest digital camera starts observing the cosmos,\" and \"India will give a \\'new form\\' to BRICS.\"\n"
          ]
        }
      ],
      "source": [
        "# ✅ Define State for Custom Agent using TypedDict\n",
        "class AgentState(TypedDict):\n",
        "    user_input: str\n",
        "    response: str\n",
        "\n",
        "# ✅ Wrap ReAct agent as node\n",
        "def run_react_agent(state: AgentState) -> AgentState:\n",
        "    \"\"\"Run the ReAct agent and update state with response\"\"\"\n",
        "    # ReAct agent takes list of messages\n",
        "    result = react_agent.invoke({\n",
        "        \"messages\": [HumanMessage(content=state[\"user_input\"])]\n",
        "    })\n",
        "\n",
        "    # Update state with response\n",
        "    state[\"response\"] = result[\"messages\"][-1].content\n",
        "    return state\n",
        "\n",
        "# ✅ Create StateGraph\n",
        "def create_custom_agent():\n",
        "    \"\"\"Create a custom agent using StateGraph\"\"\"\n",
        "\n",
        "    # Create the graph\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add the ReAct agent node\n",
        "    workflow.add_node(\"react_agent\", run_react_agent)\n",
        "\n",
        "    # Define the flow\n",
        "    workflow.add_edge(START, \"react_agent\")\n",
        "    workflow.add_edge(\"react_agent\", END)\n",
        "\n",
        "    # Compile the graph\n",
        "    return workflow.compile()\n",
        "\n",
        "# ✅ Test the custom StateGraph agent\n",
        "print(\"\\n=== Testing Custom StateGraph Agent ===\")\n",
        "custom_agent = create_custom_agent()\n",
        "\n",
        "# Test with initial state\n",
        "initial_state = {\n",
        "    \"user_input\": \"What's the weather like in New Delhi today?\",\n",
        "    \"response\": \"\"\n",
        "}\n",
        "\n",
        "result = custom_agent.invoke(initial_state)\n",
        "print(f\"User Input: {result['user_input']}\")\n",
        "print(f\"Agent Response: {result['response']}\")\n",
        "\n",
        "# ✅ Another test with news query\n",
        "print(\"\\n=== Testing News Query ===\")\n",
        "news_state = {\n",
        "    \"user_input\": \"Give me the latest technology news in India\",\n",
        "    \"response\": \"\"\n",
        "}\n",
        "\n",
        "news_result = custom_agent.invoke(news_state)\n",
        "print(f\"User Input: {news_result['user_input']}\")\n",
        "print(f\"Agent Response: {news_result['response']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h5WOlZEYipw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmUp7SOMYimz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtdSVsYkYijz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMK4M8n_Yi64"
      },
      "source": [
        "### Complex langgraph workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPMSW8ZNYihP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J9m-CPAGMdt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDLhPrDqGMbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCAY6FTGGMXi",
        "outputId": "15279b65-419a-4ff2-acc1-bf1221aeba84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=======================🚀 TEST CASE 1 =======================\n",
            "Query: What's the weather like in Delhi and give me latest technology news?\n",
            "\n",
            "🔄 [2025-07-11T08:49:24.778243] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:24.778243] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: weather, Entities: {'city': 'Delhi', 'topic': 'technology'}\n",
            "\n",
            "🔄 [2025-07-11T08:49:24.778243] NODE: weather_node | STATUS: STARTED\n",
            "Received user data for weather search: city='Delhi' unit='Celsius' of type <class '__main__.WeatherSearchInput'>\n",
            "\n",
            "🔄 [2025-07-11T08:49:27.613345] NODE: weather_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved weather for Delhi\n",
            "\n",
            "🔄 [2025-07-11T08:49:27.613345] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:30.204520] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content=\"Okay, here's the weather information for Delhi, organized into concise points:\\n\\n*   **Location:** Delhi, Ontario, Canada\\n*   **Temperature:** 22.3°C (72.1°F)\\n*   **Condition:** Fog\\n*   **Wind:** 8.3 km/h from the West\\n*   **Humidity:** 93%\\n*   **Feels Like:** 24.8°C\\n*   **July Temperatures:** Highs between 30.5°C (87°F) and 37.8°C (100°F).\\n*   **Recommendation:** Drink water regularly due to high temperatures in July.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--ffe97d03-927b-4a3f-9699-bf2bfc32cc50-0'\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Okay, here's the weather information for Delhi, organized into concise points:\n",
            "\n",
            "*   **Location:** Delhi, Ontario, Canada\n",
            "*   **Temperature:** 22.3°C (72.1°F)\n",
            "*   **Condition:** Fog\n",
            "*   **Wind:** 8.3 km/h from the West\n",
            "*   **Humidity:** 93%\n",
            "*   **Feels Like:** 24.8°C\n",
            "*   **July Temperatures:** Highs between 30.5°C (87°F) and 37.8°C (100°F).\n",
            "*   **Recommendation:** Drink water regularly due to high temperatures in July.\n",
            "\n",
            "============================================================\n",
            "\n",
            "=======================🚀 TEST CASE 2 =======================\n",
            "Query: Search for information about latest model of xai, grok and its information\n",
            "\n",
            "🔄 [2025-07-11T08:49:30.206470] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:30.206470] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: search, Entities: {}\n",
            "\n",
            "🔄 [2025-07-11T08:49:30.206470] NODE: general_search_node | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:32.322812] NODE: general_search_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved search results for: Search for information about latest model of xai, grok and its information\n",
            "\n",
            "🔄 [2025-07-11T08:49:32.323792] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:33.647214] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content='Okay, here\\'s a concise summary of the information about xAI\\'s Grok model, based on the search results:\\n\\n*   **Grok 4:** xAI has launched Grok 4, their latest flagship AI model.\\n*   **Subscription:** Access to Grok 4 is likely tied to a new $300-per-month AI subscription.\\n*   **Grok 3:** xAI has unveiled an early preview of Grok 3, described as their most advanced model yet, blending superior reasoning with extensive pretraining knowledge.\\n*   **Purpose:** Grok was launched in 2023 as an alternative to other \"woke\" bots.' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--8506e0f3-a406-4b46-aa99-1415bc3e17d2-0'\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Okay, here's a concise summary of the information about xAI's Grok model, based on the search results:\n",
            "\n",
            "*   **Grok 4:** xAI has launched Grok 4, their latest flagship AI model.\n",
            "*   **Subscription:** Access to Grok 4 is likely tied to a new $300-per-month AI subscription.\n",
            "*   **Grok 3:** xAI has unveiled an early preview of Grok 3, described as their most advanced model yet, blending superior reasoning with extensive pretraining knowledge.\n",
            "*   **Purpose:** Grok was launched in 2023 as an alternative to other \"woke\" bots.\n",
            "\n",
            "============================================================\n",
            "\n",
            "=======================🚀 TEST CASE 3 =======================\n",
            "Query: Give me news related to latest IPOs in india\n",
            "\n",
            "🔄 [2025-07-11T08:49:33.647214] NODE: intent_classifier | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:33.647214] NODE: intent_classifier | STATUS: SUCCESS\n",
            "   📝 Details: Intent: news, Entities: {}\n",
            "\n",
            "🔄 [2025-07-11T08:49:33.648191] NODE: news_node | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:35.918260] NODE: news_node | STATUS: SUCCESS\n",
            "   📝 Details: Retrieved news for general in India\n",
            "\n",
            "🔄 [2025-07-11T08:49:35.919235] NODE: response_synthesizer | STATUS: STARTED\n",
            "\n",
            "🔄 [2025-07-11T08:49:37.156490] NODE: response_synthesizer | STATUS: SUCCESS\n",
            "   📝 Details: Final response created\n",
            "Final Response in synthesizer: content=\"Here's a concise summary of the news information provided:\\n\\n*   **Indian Army Agniveer Recruitment:** The Indian Army began Agniveer 2025 recruitment exams on June 30, 2025.\\n*   **General Admits Losses:** General Anil Chauhan admitted India experienced aerial losses in a recent conflict with Pakistan.\\n*   **Zonal Councils:** Amit Shah stated that Zonal councils have transformed into engines of cooperation.\\n*   **Kerala Judge on Religious Identity:** A Kerala judge commented that kids enrolled in schools without religious identity are a future hope.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--cc823243-ee24-4337-ac7b-53e6cfc50f0e-0'\n",
            "\n",
            "======================📋 FINAL RESULT =======================\n",
            "Here's a concise summary of the news information provided:\n",
            "\n",
            "*   **Indian Army Agniveer Recruitment:** The Indian Army began Agniveer 2025 recruitment exams on June 30, 2025.\n",
            "*   **General Admits Losses:** General Anil Chauhan admitted India experienced aerial losses in a recent conflict with Pakistan.\n",
            "*   **Zonal Councils:** Amit Shah stated that Zonal councils have transformed into engines of cooperation.\n",
            "*   **Kerala Judge on Religious Identity:** A Kerala judge commented that kids enrolled in schools without religious identity are a future hope.\n",
            "\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Import standard libraries\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict, List, Optional, Literal\n",
        "from pprint import pprint\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Import the LangChain components\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Import Pydantic for structured inputs\n",
        "from pydantic import BaseModel\n",
        "\n",
        "# Import ReAct agent creation\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# API keys setup\n",
        "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Google Gemini API key: \")\n",
        "if not os.environ.get(\"TAVILY_API_KEY\"):\n",
        "    os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"Tavily API key: \")\n",
        "\n",
        "# Model initialization\n",
        "model = init_chat_model(\n",
        "    \"gemini-2.0-flash\",\n",
        "    model_provider=\"google_genai\"\n",
        ")\n",
        "\n",
        "# TavilySearch instance\n",
        "search_instance = TavilySearch(max_results=3)\n",
        "\n",
        "# ===== PYDANTIC SCHEMAS =====\n",
        "class WebSearchInput(BaseModel):\n",
        "    query: str\n",
        "    num_results: int = 2\n",
        "\n",
        "class WeatherSearchInput(BaseModel):\n",
        "    city: str\n",
        "    unit: str = \"Celsius\"\n",
        "\n",
        "class NewsSearchInput(BaseModel):\n",
        "    topic: str\n",
        "    region: str\n",
        "\n",
        "# ===== TOOLS =====\n",
        "@tool\n",
        "def search_web(query: str, num_results: int = 2) -> str:\n",
        "    \"\"\"Search the web with a query and number of results.\"\"\"\n",
        "    search_temp = TavilySearch(max_results=num_results)\n",
        "    result = search_temp.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "@tool\n",
        "def search_weather(usrdata:WeatherSearchInput) -> str:\n",
        "    \"\"\"Search weather information for a city.\"\"\"\n",
        "    print(f\"Received user data for weather search: {usrdata} of type {type(usrdata)}\")\n",
        "    # Use the Pydantic model to access city and unit\n",
        "    query = f\"current weather in {usrdata.city} in {usrdata.unit}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "# def search_weather(city: str, unit: str = \"Celsius\") -> str:\n",
        "#     \"\"\"Search weather information for a city.\"\"\"\n",
        "#     query = f\"current weather in {city} in {unit}\"\n",
        "#     result = search_instance.invoke(query)\n",
        "#     return str(result)\n",
        "\n",
        "@tool\n",
        "def search_news(topic: str, region: str = \"India\") -> str:\n",
        "    \"\"\"Search recent news headlines for a topic in a specific region.\"\"\"\n",
        "    query = f\"latest news about {topic} in {region}\"\n",
        "    result = search_instance.invoke(query)\n",
        "    return str(result)\n",
        "\n",
        "# ===== COMPLEX STATE DEFINITION =====\n",
        "class ComplexAgentState(TypedDict):\n",
        "    # Input\n",
        "    user_input: str\n",
        "\n",
        "    # Processing stages\n",
        "    intent: Optional[str]\n",
        "    entities: Optional[dict]\n",
        "\n",
        "    # Results from different nodes\n",
        "    weather_data: Optional[str]\n",
        "    news_data: Optional[str]\n",
        "    general_search_data: Optional[str]\n",
        "\n",
        "    # Error handling\n",
        "    errors: List[str]\n",
        "    retry_count: int\n",
        "\n",
        "    # Node execution tracking\n",
        "    execution_log: List[dict]\n",
        "\n",
        "    # Final output\n",
        "    final_response: str\n",
        "\n",
        "    # Control flow\n",
        "    next_action: Optional[str]\n",
        "\n",
        "# ===== UTILITY FUNCTIONS =====\n",
        "def log_execution(state: ComplexAgentState, node_name: str, status: str, details: str = \"\"):\n",
        "    \"\"\"Log node execution for debugging\"\"\"\n",
        "    timestamp = datetime.now().isoformat()\n",
        "    log_entry = {\n",
        "        \"timestamp\": timestamp,\n",
        "        \"node\": node_name,\n",
        "        \"status\": status,\n",
        "        \"details\": details\n",
        "    }\n",
        "\n",
        "    if \"execution_log\" not in state:\n",
        "        state[\"execution_log\"] = []\n",
        "\n",
        "    state[\"execution_log\"].append(log_entry)\n",
        "\n",
        "    # Pretty print for real-time monitoring\n",
        "    print(f\"\\n🔄 [{timestamp}] NODE: {node_name} | STATUS: {status}\")\n",
        "    if details:\n",
        "        print(f\"   📝 Details: {details}\")\n",
        "\n",
        "def pretty_print_state(state: ComplexAgentState, title: str):\n",
        "    \"\"\"Pretty print the current state\"\"\"\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"📊 {title}\")\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "    for key, value in state.items():\n",
        "        if key == \"execution_log\":\n",
        "            continue  # Skip execution log in state dump\n",
        "\n",
        "        if isinstance(value, str) and len(value) > 100:\n",
        "            print(f\"{key}: {value[:100]}...\")\n",
        "        else:\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "    print(f\"{'='*50}\")\n",
        "\n",
        "# ===== NODE FUNCTIONS =====\n",
        "\n",
        "def intent_classifier(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Classify user intent and extract entities\"\"\"\n",
        "    log_execution(state, \"intent_classifier\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        user_input = state[\"user_input\"].lower()\n",
        "\n",
        "        # Simple intent classification\n",
        "        if \"weather\" in user_input:\n",
        "            state[\"intent\"] = \"weather\"\n",
        "        elif \"news\" in user_input:\n",
        "            state[\"intent\"] = \"news\"\n",
        "        elif any(word in user_input for word in [\"search\", \"find\", \"look\"]):\n",
        "            state[\"intent\"] = \"search\"\n",
        "        else:\n",
        "            state[\"intent\"] = \"general\"\n",
        "\n",
        "        # Extract entities (simple keyword extraction)\n",
        "        entities = {}\n",
        "\n",
        "        # Extract city names (simple approach)\n",
        "        cities = [\"delhi\", \"mumbai\", \"bangalore\", \"chennai\", \"kolkata\", \"hyderabad\"]\n",
        "        for city in cities:\n",
        "            if city in user_input:\n",
        "                entities[\"city\"] = city.title()\n",
        "                break\n",
        "\n",
        "        # Extract topics\n",
        "        if \"technology\" in user_input or \"tech\" in user_input:\n",
        "            entities[\"topic\"] = \"technology\"\n",
        "        elif \"sports\" in user_input:\n",
        "            entities[\"topic\"] = \"sports\"\n",
        "        elif \"politics\" in user_input:\n",
        "            entities[\"topic\"] = \"politics\"\n",
        "\n",
        "        state[\"entities\"] = entities\n",
        "\n",
        "        log_execution(state, \"intent_classifier\", \"SUCCESS\",\n",
        "                     f\"Intent: {state['intent']}, Entities: {entities}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Intent classification failed: {str(e)}\")\n",
        "        log_execution(state, \"intent_classifier\", \"ERROR\", str(e))\n",
        "        return state\n",
        "\n",
        "def weather_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle weather-related queries\"\"\"\n",
        "    log_execution(state, \"weather_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        entities = state.get(\"entities\", {})\n",
        "        city = entities.get(\"city\", \"New Delhi\")  # Default city\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_weather.invoke({\"usrdata\": {\"city\": \"Delhi\", \"unit\": \"Celsius\"}})\n",
        "\n",
        "        state[\"weather_data\"] = result\n",
        "        log_execution(state, \"weather_node\", \"SUCCESS\", f\"Retrieved weather for {city}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Weather search failed: {str(e)}\")\n",
        "        log_execution(state, \"weather_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def news_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle news-related queries\"\"\"\n",
        "    log_execution(state, \"news_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        entities = state.get(\"entities\", {})\n",
        "        topic = entities.get(\"topic\", \"general\")\n",
        "        region = entities.get(\"city\", \"India\")\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_news.invoke({\"topic\": topic, \"region\": region})\n",
        "\n",
        "        state[\"news_data\"] = result\n",
        "        log_execution(state, \"news_node\", \"SUCCESS\", f\"Retrieved news for {topic} in {region}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"News search failed: {str(e)}\")\n",
        "        log_execution(state, \"news_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def general_search_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle general search queries\"\"\"\n",
        "    log_execution(state, \"general_search_node\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        query = state[\"user_input\"]\n",
        "\n",
        "        # Call the tool directly with parameters\n",
        "        result = search_web.invoke({\"query\": query, \"num_results\": 3})\n",
        "\n",
        "        state[\"general_search_data\"] = result\n",
        "        log_execution(state, \"general_search_node\", \"SUCCESS\", f\"Retrieved search results for: {query}\")\n",
        "\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"General search failed: {str(e)}\")\n",
        "        log_execution(state, \"general_search_node\", \"ERROR\", str(e))\n",
        "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
        "        return state\n",
        "\n",
        "def error_handler_node(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Handle errors and decide on retries\"\"\"\n",
        "    log_execution(state, \"error_handler_node\", \"STARTED\")\n",
        "\n",
        "    retry_count = state.get(\"retry_count\", 0)\n",
        "\n",
        "    if retry_count < 2:  # Max 2 retries\n",
        "        log_execution(state, \"error_handler_node\", \"RETRY\", f\"Retry attempt {retry_count + 1}\")\n",
        "        state[\"next_action\"] = \"retry\"\n",
        "    else:\n",
        "        log_execution(state, \"error_handler_node\", \"GIVE_UP\", \"Max retries reached\")\n",
        "        state[\"next_action\"] = \"finalize\"\n",
        "\n",
        "    return state\n",
        "\n",
        "def response_synthesizer(state: ComplexAgentState) -> ComplexAgentState:\n",
        "    \"\"\"Synthesize final response from all collected data\"\"\"\n",
        "    log_execution(state, \"response_synthesizer\", \"STARTED\")\n",
        "\n",
        "    try:\n",
        "        response_parts = []\n",
        "\n",
        "        # Add weather data if available\n",
        "        if state.get(\"weather_data\"):\n",
        "            response_parts.append(f\"🌤️ Weather Information:\\n{state['weather_data']}\")\n",
        "\n",
        "        # Add news data if available\n",
        "        if state.get(\"news_data\"):\n",
        "            response_parts.append(f\"📰 News Information:\\n{state['news_data']}\")\n",
        "\n",
        "        # Add general search data if available\n",
        "        if state.get(\"general_search_data\"):\n",
        "            response_parts.append(f\"🔍 Search Results:\\n{state['general_search_data']}\")\n",
        "\n",
        "        # Handle errors\n",
        "        if state.get(\"errors\"):\n",
        "            response_parts.append(f\"⚠️ Errors encountered:\\n\" + \"\\n\".join(state[\"errors\"]))\n",
        "\n",
        "        # Create final response\n",
        "        if response_parts:\n",
        "            final_response = \"\\n\\n\".join(response_parts)\n",
        "        else:\n",
        "            final_response = \"I apologize, but I couldn't retrieve any information for your query.\"\n",
        "\n",
        "        final_response = model.invoke([{\"role\": \"assistant\", \"content\": final_response},\n",
        "                      {\"role\": \"user\", \"content\": \"Organize this information into a concise pointwise response.\"},\n",
        "                      ])\n",
        "\n",
        "        state[\"final_response\"] = final_response.content\n",
        "        log_execution(state, \"response_synthesizer\", \"SUCCESS\", \"Final response created\")\n",
        "        print(f\"Final Response in synthesizer: {final_response}\")\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"errors\"].append(f\"Response synthesis failed: {str(e)}\")\n",
        "        log_execution(state, \"response_synthesizer\", \"ERROR\", str(e))\n",
        "        state[\"final_response\"] = \"An error occurred while processing your request.\"\n",
        "        return state\n",
        "\n",
        "# ===== ROUTING FUNCTIONS =====\n",
        "\n",
        "def should_get_weather(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should get weather data\"\"\"\n",
        "    return state.get(\"intent\") in [\"weather\", \"general\"] and not state.get(\"weather_data\")\n",
        "\n",
        "def should_get_news(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should get news data\"\"\"\n",
        "    return state.get(\"intent\") in [\"news\", \"general\"] and not state.get(\"news_data\")\n",
        "\n",
        "def should_do_general_search(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should do general search\"\"\"\n",
        "    return state.get(\"intent\") == \"search\" and not state.get(\"general_search_data\")\n",
        "\n",
        "def should_handle_error(state: ComplexAgentState) -> bool:\n",
        "    \"\"\"Check if we should handle errors\"\"\"\n",
        "    return len(state.get(\"errors\", [])) > 0 and state.get(\"retry_count\", 0) < 2\n",
        "\n",
        "def route_after_classification(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after intent classification\"\"\"\n",
        "    if should_handle_error(state):\n",
        "        return \"handle_error\"\n",
        "    elif should_get_weather(state):\n",
        "        return \"weather\"\n",
        "    elif should_get_news(state):\n",
        "        return \"news\"\n",
        "    elif should_do_general_search(state):\n",
        "        return \"general_search\"\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "def route_after_data_collection(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after data collection nodes\"\"\"\n",
        "    if should_handle_error(state):\n",
        "        return \"handle_error\"\n",
        "    elif should_get_weather(state):\n",
        "        return \"weather\"\n",
        "    elif should_get_news(state):\n",
        "        return \"news\"\n",
        "    elif should_do_general_search(state):\n",
        "        return \"general_search\"\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "def route_after_error_handler(state: ComplexAgentState) -> str:\n",
        "    \"\"\"Route after error handling\"\"\"\n",
        "    if state.get(\"next_action\") == \"retry\":\n",
        "        return route_after_classification(state)\n",
        "    else:\n",
        "        return \"synthesizer\"\n",
        "\n",
        "# ===== CREATE COMPLEX WORKFLOW =====\n",
        "\n",
        "def create_complex_workflow():\n",
        "    \"\"\"Create a complex workflow with multiple nodes and error handling\"\"\"\n",
        "\n",
        "    workflow = StateGraph(ComplexAgentState)\n",
        "\n",
        "    # Add all nodes\n",
        "    workflow.add_node(\"classifier\", intent_classifier)\n",
        "    workflow.add_node(\"weather\", weather_node)\n",
        "    workflow.add_node(\"news\", news_node)\n",
        "    workflow.add_node(\"general_search\", general_search_node)\n",
        "    workflow.add_node(\"handle_error\", error_handler_node)\n",
        "    workflow.add_node(\"synthesizer\", response_synthesizer)\n",
        "\n",
        "    # Define edges\n",
        "    workflow.add_edge(START, \"classifier\")\n",
        "\n",
        "    # Conditional edges from classifier\n",
        "    workflow.add_conditional_edges(\n",
        "        \"classifier\",\n",
        "        route_after_classification,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Conditional edges from data collection nodes\n",
        "    workflow.add_conditional_edges(\n",
        "        \"weather\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"news\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_conditional_edges(\n",
        "        \"general_search\",\n",
        "        route_after_data_collection,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"handle_error\": \"handle_error\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Error handler routing\n",
        "    workflow.add_conditional_edges(\n",
        "        \"handle_error\",\n",
        "        route_after_error_handler,\n",
        "        {\n",
        "            \"weather\": \"weather\",\n",
        "            \"news\": \"news\",\n",
        "            \"general_search\": \"general_search\",\n",
        "            \"synthesizer\": \"synthesizer\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # End at synthesizer\n",
        "    workflow.add_edge(\"synthesizer\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "\n",
        "# ===== TEST THE COMPLEX WORKFLOW =====\n",
        "\n",
        "def test_complex_workflow():\n",
        "    \"\"\"Test the complex workflow with different queries\"\"\"\n",
        "\n",
        "    # Create the workflow\n",
        "    complex_agent = create_complex_workflow()\n",
        "\n",
        "    # Test cases\n",
        "    test_cases = [\n",
        "        \"What's the weather like in Delhi and give me latest technology news?\",\n",
        "        \"Search for information about latest model of xai, grok and its information\",\n",
        "        \"Give me news related to latest IPOs in india\",\n",
        "    ]\n",
        "\n",
        "    for i, query in enumerate(test_cases, 1):\n",
        "        print(f\"\\n{'🚀 TEST CASE ' + str(i) + ' ':=^60}\")\n",
        "        print(f\"Query: {query}\")\n",
        "\n",
        "        # Create initial state\n",
        "        initial_state = {\n",
        "            \"user_input\": query,\n",
        "            \"intent\": None,\n",
        "            \"entities\": None,\n",
        "            \"weather_data\": None,\n",
        "            \"news_data\": None,\n",
        "            \"general_search_data\": None,\n",
        "            \"errors\": [],\n",
        "            \"retry_count\": 0,\n",
        "            \"execution_log\": [],\n",
        "            \"final_response\": \"\",\n",
        "            \"next_action\": None\n",
        "        }\n",
        "\n",
        "        # Run the workflow\n",
        "        result = complex_agent.invoke(initial_state)\n",
        "\n",
        "        # Show final result\n",
        "        print(f\"\\n{'📋 FINAL RESULT ':=^60}\")\n",
        "        print(result[\"final_response\"])\n",
        "\n",
        "        # # Show execution log\n",
        "        # print(f\"\\n{'📊 EXECUTION LOG ':=^60}\")\n",
        "        # for log_entry in result[\"execution_log\"]:\n",
        "        #     print(f\"[{log_entry['timestamp']}] {log_entry['node']} - {log_entry['status']}\")\n",
        "        #     if log_entry['details']:\n",
        "        #         print(f\"   {log_entry['details']}\")\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "\n",
        "# Run the test\n",
        "if __name__ == \"__main__\":\n",
        "    test_complex_workflow()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
